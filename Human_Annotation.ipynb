{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d279ba94-cf8e-49c5-a70a-e4a1ede9f8ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nervaluate import Evaluator\n",
    "import seqeval.metrics\n",
    "import sklearn.metrics\n",
    "import tqdm\n",
    "from compute_f1_qa import calculate_mean_ci"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1ccd5878-fad0-4f24-adc8-cb234cfeb033",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_dir = '/scratch/dzhang5/usda_project/tweet-fid-application'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a107539d-fed4-4496-8bcf-1a3cac69a86d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mv_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_mv/train.p\")\n",
    "train_expert_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_expert_label/train.p\")\n",
    "train_bsc_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_BSC/train.p\")\n",
    "test_expert_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_expert_label/test.p\")\n",
    "test_mv_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_mv/test.p\")\n",
    "test_bsc_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_BSC/test.p\")\n",
    "dev_expert_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_expert_label/dev.p\")\n",
    "dev_mv_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_mv/dev.p\")\n",
    "dev_bsc_data = pd.read_pickle(f\"{tweet_dir}/tweet-fid/LREC_BSC/dev.p\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1826e36-50a4-4ddf-b681-50bee76bdf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_test_expert_data = pd.concat([train_expert_data, test_expert_data])\n",
    "train_test_mv_data = pd.concat([train_mv_data, test_mv_data])\n",
    "train_test_bsc_data = pd.concat([train_bsc_data, test_bsc_data])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7380affd-33a8-4d76-a06c-e496c81a105a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap_time = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4363f974-18cb-4b84-a86d-3e44133ada9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = ['food', 'loc', 'symptom', 'keyword']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5a1d38ff-dfcd-4e5e-b705-869e26e12233",
   "metadata": {},
   "outputs": [],
   "source": [
    "expert_label = train_test_expert_data['relevant_entity_label']\n",
    "bsc_label = train_test_bsc_data['relevant_entity_label']\n",
    "mv_label = train_test_mv_data['relevant_entity_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "19fec29c-ffa2-4e0e-8a8a-3b737992724d",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = pd.DataFrame({'expert':expert_label, 'bsc':bsc_label, 'mv':mv_label})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3840c49-1494-428d-a433-f8757a5e8c94",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_truncate(label, pred):\n",
    "    ll, pl = len(label), len(pred)\n",
    "    if ll == pl:\n",
    "        return pred\n",
    "    elif ll > pl:\n",
    "        return pred + ['O']*(ll - pl)\n",
    "    else:\n",
    "        return pred[:ll]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5c8454b4-5bbe-47b9-b7e0-834958344eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels['bsc'] = all_labels[['expert', 'bsc']].apply(lambda x: pad_truncate(x['expert'], x['bsc']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8682eb2f-f463-4370-908e-3e41e16d68d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels['mv'] = all_labels[['expert', 'mv']].apply(lambda x: pad_truncate(x['expert'], x['mv']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e68c5fe8-3e38-42e6-a398-08c5902f1cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent_type\n",
      "{'correct': 1102, 'incorrect': 37, 'partial': 0, 'missed': 252, 'spurious': 920, 'possible': 1391, 'actual': 2059, 'precision': 0.5352112676056338, 'recall': 0.792235801581596, 'f1': 0.638840579710145}\n",
      "partial\n",
      "{'correct': 960, 'incorrect': 0, 'partial': 179, 'missed': 252, 'spurious': 920, 'possible': 1391, 'actual': 2059, 'precision': 0.5097134531325886, 'recall': 0.7544931703810208, 'f1': 0.6084057971014493}\n",
      "strict\n",
      "{'correct': 936, 'incorrect': 203, 'partial': 0, 'missed': 252, 'spurious': 920, 'possible': 1391, 'actual': 2059, 'precision': 0.45458960660514813, 'recall': 0.6728971962616822, 'f1': 0.542608695652174}\n",
      "exact\n",
      "{'correct': 960, 'incorrect': 179, 'partial': 0, 'missed': 252, 'spurious': 920, 'possible': 1391, 'actual': 2059, 'precision': 0.4662457503642545, 'recall': 0.6901509705248023, 'f1': 0.5565217391304348}\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(all_labels['expert'].tolist(), all_labels['bsc'].tolist(), tags=labels, loader=\"list\")\n",
    "results, results_by_tag = evaluator.evaluate()\n",
    "for key, val in results.items():\n",
    "    print(key)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2b2a58be-bcb4-4d30-a8f1-5eddbf964c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ent_type\n",
      "{'correct': 1007, 'incorrect': 31, 'partial': 0, 'missed': 353, 'spurious': 726, 'possible': 1391, 'actual': 1764, 'precision': 0.5708616780045351, 'recall': 0.723939611790079, 'f1': 0.6383518225039619}\n",
      "partial\n",
      "{'correct': 957, 'incorrect': 0, 'partial': 81, 'missed': 353, 'spurious': 726, 'possible': 1391, 'actual': 1764, 'precision': 0.5654761904761905, 'recall': 0.7171099928109274, 'f1': 0.6323296354992076}\n",
      "strict\n",
      "{'correct': 935, 'incorrect': 103, 'partial': 0, 'missed': 353, 'spurious': 726, 'possible': 1391, 'actual': 1764, 'precision': 0.530045351473923, 'recall': 0.6721782890007189, 'f1': 0.5927099841521395}\n",
      "exact\n",
      "{'correct': 957, 'incorrect': 81, 'partial': 0, 'missed': 353, 'spurious': 726, 'possible': 1391, 'actual': 1764, 'precision': 0.5425170068027211, 'recall': 0.6879942487419123, 'f1': 0.6066561014263074}\n"
     ]
    }
   ],
   "source": [
    "evaluator = Evaluator(all_labels['expert'].tolist(), all_labels['mv'].tolist(), tags=labels, loader=\"list\")\n",
    "results, results_by_tag = evaluator.evaluate()\n",
    "for key, val in results.items():\n",
    "    print(key)\n",
    "    print(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "00d59a64-b0f2-4776-bc3d-ed368feafa5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:51<00:00,  1.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:\n",
      "mean:  0.5908 ±  0.0146\n",
      "lower 95% CI:  0.5598\n",
      "upper 95% CI:  0.6156\n",
      "precision:\n",
      "mean:  0.5286 ±  0.0165\n",
      "lower 95% CI:  0.4936\n",
      "upper 95% CI:  0.5607\n",
      "recall:\n",
      "mean:  0.6701 ±  0.0160\n",
      "lower 95% CI:  0.6356\n",
      "upper 95% CI:  0.7009\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = all_labels.index\n",
    "rng = np.random.RandomState(seed=12345)\n",
    "f1_list, pre_list, rec_list = [], [], []\n",
    "for _ in tqdm.trange(bootstrap_time):\n",
    "    pred_idx = rng.choice(idx, size=idx.shape[0], replace=True)\n",
    "    keep_labels = all_labels['expert'][pred_idx]\n",
    "    keep_preds = all_labels['mv'][pred_idx]\n",
    "    evaluator = Evaluator(keep_labels, keep_preds, tags=labels, loader=\"list\")\n",
    "    results, results_by_tag = evaluator.evaluate()\n",
    "    f1_list.append(results[\"strict\"]['f1'])\n",
    "    pre_list.append(results[\"strict\"]['precision'])\n",
    "    rec_list.append(results[\"strict\"]['recall'])\n",
    "\n",
    "f1_str = calculate_mean_ci(f1_list)\n",
    "pre_str = calculate_mean_ci(pre_list)\n",
    "rec_str = calculate_mean_ci(rec_list)\n",
    "print(f'F1:\\n{f1_str}\\nprecision:\\n{pre_str}\\nrecall:\\n{rec_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0bd85b68-f0fa-4189-88ae-6822f34b3df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [02:50<00:00,  1.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1:\n",
      "mean:  0.5414 ±  0.0141\n",
      "lower 95% CI:  0.5138\n",
      "upper 95% CI:  0.5694\n",
      "precision:\n",
      "mean:  0.4539 ±  0.0150\n",
      "lower 95% CI:  0.4234\n",
      "upper 95% CI:  0.4832\n",
      "recall:\n",
      "mean:  0.6711 ±  0.0157\n",
      "lower 95% CI:  0.6388\n",
      "upper 95% CI:  0.7011\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = all_labels.index\n",
    "rng = np.random.RandomState(seed=12345)\n",
    "f1_list, pre_list, rec_list = [], [], []\n",
    "for _ in tqdm.trange(bootstrap_time):\n",
    "    pred_idx = rng.choice(idx, size=idx.shape[0], replace=True)\n",
    "    keep_labels = all_labels['expert'][pred_idx]\n",
    "    keep_preds = all_labels['bsc'][pred_idx]\n",
    "    evaluator = Evaluator(keep_labels, keep_preds, tags=labels, loader=\"list\")\n",
    "    results, results_by_tag = evaluator.evaluate()\n",
    "    f1_list.append(results[\"strict\"]['f1'])\n",
    "    pre_list.append(results[\"strict\"]['precision'])\n",
    "    rec_list.append(results[\"strict\"]['recall'])\n",
    "\n",
    "f1_str = calculate_mean_ci(f1_list)\n",
    "pre_str = calculate_mean_ci(pre_list)\n",
    "rec_str = calculate_mean_ci(rec_list)\n",
    "print(f'F1:\\n{f1_str}\\nprecision:\\n{pre_str}\\nrecall:\\n{rec_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "828ae395-12f4-47b4-89b4-3b95f4df7bf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        food     0.4977    0.6866    0.5771       469\n",
      "         loc     0.5299    0.6577    0.5869       485\n",
      "       other     0.6202    0.8823    0.7284      1257\n",
      "     symptom     0.3642    0.6751    0.4731       437\n",
      "\n",
      "   micro avg     0.5316    0.7723    0.6297      2648\n",
      "   macro avg     0.5030    0.7254    0.5914      2648\n",
      "weighted avg     0.5397    0.7723    0.6336      2648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = seqeval.metrics.classification_report(all_labels['expert'], all_labels['bsc'], zero_division=1, digits=4)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "cc95bcc9-5c19-4c51-ab43-2942ea59916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        food     0.5503    0.6994    0.6160       469\n",
      "         loc     0.6360    0.6557    0.6457       485\n",
      "       other     0.6360    0.8799    0.7383      1257\n",
      "     symptom     0.4326    0.6613    0.5231       437\n",
      "\n",
      "   micro avg     0.5826    0.7708    0.6636      2648\n",
      "   macro avg     0.5637    0.7241    0.6308      2648\n",
      "weighted avg     0.5873    0.7708    0.6642      2648\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = seqeval.metrics.classification_report(all_labels['expert'], all_labels['mv'], zero_division=1, digits=4)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7cb9fb85-fb8e-4465-b5c9-e302c258ce93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(train_test_expert_data.index == train_test_mv_data.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ba77cb2f-4a1e-493e-ae05-1a33cd0f7fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 200/200 [00:01<00:00, 146.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc:\n",
      "mean:  0.8195 ±  0.0059\n",
      "lower 95% CI:  0.8075\n",
      "upper 95% CI:  0.8297\n",
      "B.Acc:\n",
      "mean:  0.8515 ±  0.0051\n",
      "lower 95% CI:  0.8426\n",
      "upper 95% CI:  0.8608\n",
      "F1:\n",
      "mean:  0.7759 ±  0.0082\n",
      "lower 95% CI:  0.7588\n",
      "upper 95% CI:  0.7907\n",
      "precision:\n",
      "mean:  0.6578 ±  0.0110\n",
      "lower 95% CI:  0.6350\n",
      "upper 95% CI:  0.6784\n",
      "recall:\n",
      "mean:  0.9459 ±  0.0062\n",
      "lower 95% CI:  0.9348\n",
      "upper 95% CI:  0.9573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "idx = train_test_expert_data.index\n",
    "rng = np.random.RandomState(seed=12345)\n",
    "acc_list, bacc_list, f1_list, pre_list, rec_list = [], [], [], [], []\n",
    "for _ in tqdm.trange(bootstrap_time):\n",
    "    pred_idx = rng.choice(idx, size=idx.shape[0], replace=True)\n",
    "    keep_labels = train_test_expert_data['sentence_class'][pred_idx]\n",
    "    keep_preds = train_test_mv_data['sentence_class'][pred_idx]\n",
    "    acc_list.append(sklearn.metrics.accuracy_score(keep_labels, keep_preds))\n",
    "    bacc_list.append(sklearn.metrics.balanced_accuracy_score(keep_labels, keep_preds))\n",
    "    f1_list.append(sklearn.metrics.f1_score(keep_labels, keep_preds, pos_label=1))\n",
    "    pre_list.append(sklearn.metrics.precision_score(keep_labels, keep_preds, pos_label=1))\n",
    "    rec_list.append(sklearn.metrics.recall_score(keep_labels, keep_preds, pos_label=1))\n",
    "\n",
    "acc_str = calculate_mean_ci(acc_list)\n",
    "bacc_str = calculate_mean_ci(bacc_list)\n",
    "f1_str = calculate_mean_ci(f1_list)\n",
    "pre_str = calculate_mean_ci(pre_list)\n",
    "rec_str = calculate_mean_ci(rec_list)\n",
    "print(f'Acc:\\n{acc_str}\\nB.Acc:\\n{bacc_str}\\nF1:\\n{f1_str}\\nprecision:\\n{pre_str}\\nrecall:\\n{rec_str}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8e05a471-cafc-4118-bce9-50fb4f20d26b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.7573    0.8491      2485\n",
      "           1     0.6578    0.9461    0.7760      1225\n",
      "\n",
      "    accuracy                         0.8197      3710\n",
      "   macro avg     0.8119    0.8517    0.8126      3710\n",
      "weighted avg     0.8643    0.8197    0.8250      3710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = sklearn.metrics.classification_report(train_test_expert_data['sentence_class'], train_test_mv_data['sentence_class'], zero_division=1, digits=4)\n",
    "print(cls_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bb9b7647-ca0a-414e-9f82-6d391fe9f1d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9661    0.7573    0.8491      2485\n",
      "           1     0.6578    0.9461    0.7760      1225\n",
      "\n",
      "    accuracy                         0.8197      3710\n",
      "   macro avg     0.8119    0.8517    0.8126      3710\n",
      "weighted avg     0.8643    0.8197    0.8250      3710\n",
      "\n"
     ]
    }
   ],
   "source": [
    "cls_report = sklearn.metrics.classification_report(train_test_expert_data['sentence_class'], train_test_bsc_data['sentence_class'], zero_division=1, digits=4)\n",
    "print(cls_report)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
