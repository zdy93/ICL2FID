{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9cdd977e-69f1-4e61-8f3e-a86ffebb8efc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "import argparse\n",
    "import re\n",
    "import os\n",
    "from sklearn.metrics import f1_score, recall_score, precision_score, accuracy_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e130994-0f5a-4192-a8a0-6faa69039701",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(labels, dir_, last_name):\n",
    "    print(\"writing ...\")\n",
    "    file_name = os.path.join(dir_, last_name)\n",
    "    file = open(file_name, \"w\")\n",
    "    for line in labels:\n",
    "        file.write(line.strip() + '\\n')\n",
    "    file.close()\n",
    "\n",
    "def read_openai_file(file_name):\n",
    "    print(f\"read ... {file_name}\")\n",
    "\n",
    "    file = open(file_name, \"r\")\n",
    "    results = []\n",
    "    for line in tqdm(file):\n",
    "        results.append(line.strip())\n",
    "    file.close()\n",
    "    return results\n",
    "\n",
    "def read_dialog_file(file_name):\n",
    "    print(f\"read ... {file_name}\")\n",
    "\n",
    "    with open(file_name, \"r\") as file:\n",
    "        dialogs = json.load(file)\n",
    "    results = [i[-1]['generation']['content'] for i in dialogs]\n",
    "    return results\n",
    "\n",
    "def read_full_dialog_file(file_name):\n",
    "    print(f\"read ... {file_name}\")\n",
    "\n",
    "    with open(file_name, \"r\") as file:\n",
    "        dialogs = json.load(file)\n",
    "    return dialogs\n",
    "\n",
    "def read_mrc_file(file_name):\n",
    "    print(f\"read ... {file_name}\")\n",
    "\n",
    "    return json.load(open(file_name))\n",
    "\n",
    "def split_and_keep_second_part(text):\n",
    "    # Regular expression pattern for any non-space character followed by a colon\n",
    "    pattern = r'[^ ]+:'\n",
    "    parts = re.split(pattern, text, maxsplit=1)\n",
    "\n",
    "    # Return the second part after removing any leading/trailing whitespace, if it exists\n",
    "    return parts[1].strip() if len(parts) > 1 else text\n",
    "\n",
    "\n",
    "def process_predictions(ori_results):\n",
    "    results = []\n",
    "    for line in ori_results:\n",
    "        line = split_and_keep_second_part(line)\n",
    "        results.append(line)\n",
    "    return results\n",
    "\n",
    "\n",
    "def compute_f1(mrc_data, openai_data):\n",
    "    print(\"computting f1 ...\")\n",
    "\n",
    "    true_positive = 0\n",
    "    false_positive = 0\n",
    "    false_negitative = 0\n",
    "    category_data = {'food':{'tp':0, 'fp':0, 'fn':0}, 'symptom':{'tp':0, 'fp':0, 'fn':0}, \n",
    "                     'loc':{'tp':0, 'fp':0, 'fn':0}, 'other':{'tp':0, 'fp':0, 'fn':0},}\n",
    "    for idx_ in range(len(mrc_data)):\n",
    "        reference = []\n",
    "        candidate = []\n",
    "        entity_list = []\n",
    "        item_ = mrc_data[idx_]\n",
    "        context_list = item_[\"context\"].strip().split()\n",
    "        entity_type = item_[\"entity_label\"]\n",
    "        for sub_idx in range(len(item_[\"start_position\"])):\n",
    "            start_ = item_[\"start_position\"][sub_idx]\n",
    "            end_ = item_[\"end_position\"][sub_idx]\n",
    "            reference.append((\" \".join(context_list[start_:end_ + 1]), start_, end_))\n",
    "\n",
    "        flag = False\n",
    "        candidate_sentence = openai_data[idx_]\n",
    "        candidate_sentence_list = candidate_sentence.strip().split()\n",
    "        start_ = 0\n",
    "        for word_idx, word in enumerate(candidate_sentence_list):\n",
    "            if len(word) > 2 and word[0] == '@' and word[1] == '@':\n",
    "                flag = True\n",
    "                for end_ in range(word_idx, len(candidate_sentence_list)):\n",
    "                    end_word = candidate_sentence_list[end_]\n",
    "                    if len(end_word) > 2 and end_word[-1] == '#' and end_word[-2] == '#':\n",
    "                        entity_ = \" \".join(candidate_sentence_list[word_idx:end_ + 1])[2:-2]\n",
    "                        len_ = end_ - word_idx + 1\n",
    "                        while start_ < len(context_list):\n",
    "                            if start_ + len_ - 1 < len(context_list) and \" \".join(\n",
    "                                    context_list[start_:start_ + len_]) == entity_:\n",
    "                                candidate.append(\n",
    "                                    (\" \".join(context_list[start_:start_ + len_]), start_, start_ + len_ - 1))\n",
    "                                break\n",
    "                            start_ += 1\n",
    "                        break\n",
    "            if len(word) > 2 and word[-1] == '#' and word[-2] == '#':\n",
    "                flag = False\n",
    "                continue\n",
    "            if not flag:\n",
    "                start_ += 1\n",
    "\n",
    "        # item_ = openai_data[idx_]\n",
    "        # context_list = item_.strip().split()\n",
    "\n",
    "        # flag = False\n",
    "        # start_ = 0\n",
    "        # for word_idx, word in enumerate(context_list):\n",
    "        #     if len(word) > 2 and word[0] == '@' and word[1] == '@':\n",
    "        #         flag = True\n",
    "        #         start_ = word_idx\n",
    "        #     if flag and len(word) > 2 and word[-1] == '#' and word[-2] == '#':\n",
    "        #         flag = False\n",
    "        #         candidate.append((\" \".join(context_list[start_:word_idx+1])[2:-2], start_, word_idx))\n",
    "\n",
    "        # print(f\"ref: {reference}\")\n",
    "        # print(f\"can: {candidate}\")\n",
    "        for span_item in candidate:\n",
    "            if span_item in reference:\n",
    "                reference.remove(span_item)\n",
    "                true_positive += 1\n",
    "                category_data[entity_type]['tp'] += 1\n",
    "            else:\n",
    "                false_positive += 1\n",
    "                category_data[entity_type]['fp'] += 1\n",
    "        false_negitative += len(reference)\n",
    "        category_data[entity_type]['fn'] += len(reference)\n",
    "\n",
    "    span_recall = true_positive / (true_positive + false_negitative)\n",
    "    span_precision = true_positive / (true_positive + false_positive)\n",
    "    span_f1 = span_precision * span_recall * 2 / (span_recall + span_precision)\n",
    "\n",
    "    return span_recall, span_precision, span_f1, true_positive, false_positive, false_negitative, category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2170fb3-3914-474b-8448-a7e6661d4657",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_label(text):\n",
    "    text = text.lower()\n",
    "    if 'yes' in text:\n",
    "        return 1\n",
    "    if 'no' in text:\n",
    "        return 0\n",
    "    return 0\n",
    "\n",
    "def compute_sentence_f1(mrc_data, openai_data):\n",
    "    y_true = [i['sentence_class'] for i in mrc_data]\n",
    "    y_pred = [convert_label(ans) for ans in openai_data]\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    f1 = f1_score(y_true, y_pred)\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return (recall, precision, f1, acc), (tn, fp, fn, tp)\n",
    "\n",
    "\n",
    "def construct_results(gpt_results, verify_results):\n",
    "    def justify(string_):\n",
    "        if len(string_) >= 3 and string_[:3].lower() == \"yes\":\n",
    "            return \"yes\"\n",
    "        if len(string_) >= 2 and string_[:2].lower() == \"no\":\n",
    "            return \"no\"\n",
    "        return \"\"\n",
    "\n",
    "    def reverse_ans(string_):\n",
    "        if len(string_) >= 3 and \"yes\" in string_.lower():\n",
    "            return \"no\"\n",
    "        if len(string_) >= 2 and \"no\" in string_.lower():\n",
    "            return \"yes\"\n",
    "        return string_\n",
    "\n",
    "    results = []\n",
    "    for idx_, item in enumerate(gpt_results):\n",
    "        ans = \" \".join(item.strip().split())\n",
    "        if justify(verify_results[idx_].strip()) == \"no\":\n",
    "            ans = reverse_ans(ans)\n",
    "        results.append(ans)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb6a3931-70bc-4054-a6fb-67cf87f86e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_simple_f1(mrc_data, openai_data, label_symbol=\"@@##\"):\n",
    "    print(\"computting f1 ...\")\n",
    "    sym_len = len(label_symbol)\n",
    "    label_prefix, label_suffix = label_symbol[:sym_len // 2], label_symbol[sym_len // 2:]\n",
    "\n",
    "    mention_true_positive, mention_false_positive, mention_false_negative = 0, 0, 0\n",
    "    mention_category_data = {'food':{'tp':0, 'fp':0, 'fn':0}, 'symptom':{'tp':0, 'fp':0, 'fn':0},\n",
    "                             'loc':{'tp':0, 'fp':0, 'fn':0}, 'other':{'tp':0, 'fp':0, 'fn':0},}\n",
    "\n",
    "    for idx_ in range(len(mrc_data)):\n",
    "        reference_word = []\n",
    "        candidate_word = []\n",
    "        item_ = mrc_data[idx_]\n",
    "        context_list = item_[\"context\"].strip().split()\n",
    "        entity_type = item_[\"entity_label\"]\n",
    "        for sub_idx in range(len(item_[\"start_position\"])):\n",
    "            start_ = item_[\"start_position\"][sub_idx]\n",
    "            end_ = item_[\"end_position\"][sub_idx]\n",
    "            reference_word.append(\" \".join(context_list[start_:end_ + 1]))\n",
    "\n",
    "        flag = False\n",
    "        candidate_sentence = openai_data[idx_]\n",
    "        candidate_sentence = candidate_sentence.strip().split(\":\")[-1]\n",
    "        candidate_sentence_list = candidate_sentence.strip().split(',')\n",
    "        candidate_word.extend(candidate_sentence_list)\n",
    "\n",
    "        for span_item in candidate_word:\n",
    "            if span_item in reference_word:\n",
    "                reference_word.remove(span_item)\n",
    "                mention_true_positive += 1\n",
    "                mention_category_data[entity_type]['tp'] += 1\n",
    "            else:\n",
    "                mention_false_positive += 1\n",
    "                mention_category_data[entity_type]['fp'] += 1\n",
    "        mention_false_negative += len(reference_word)\n",
    "        mention_category_data[entity_type]['fn'] += len(reference_word)\n",
    "\n",
    "    mention_recall = mention_true_positive / (mention_true_positive + mention_false_negative)\n",
    "    mention_precision = mention_true_positive / (mention_true_positive + mention_false_positive)\n",
    "    mention_f1 = mention_precision * mention_recall * 2 / (mention_recall + mention_precision)\n",
    "    mention_all_count = {'tp': mention_true_positive, 'fp': mention_false_positive, 'fn': mention_false_negative}\n",
    "    return mention_recall, mention_precision, mention_f1, mention_all_count, mention_category_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5ef3bd92-78a1-4033-9625-60c859d21a49",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tweet_results(gpt_results, verify_results, pos_word, neg_word):\n",
    "    # def justify(string_):\n",
    "    #     if len(string_) >= 3 and string_[:3].lower() == \"yes\":\n",
    "    #         return \"yes\"\n",
    "    #     if len(string_) >= 2 and string_[:2].lower() == \"no\":\n",
    "    #         return \"no\"\n",
    "    #     return \"\"\n",
    "    def justify(string_):\n",
    "        if \"yes\" in string_.lower():\n",
    "            return \"yes\"\n",
    "        if \"no\" in string_.lower():\n",
    "            return \"no\"\n",
    "        return \"\"\n",
    "\n",
    "    def reverse_ans(string_, pos_word, neg_word):\n",
    "        if len(string_) >= 3 and pos_word in string_.lower():\n",
    "            return neg_word\n",
    "        if len(string_) >= 2 and neg_word in string_.lower():\n",
    "            return pos_word\n",
    "        return string_\n",
    "\n",
    "    results = []\n",
    "    for idx_, item in enumerate(gpt_results):\n",
    "        ans = \" \".join(item.strip().split())\n",
    "        if justify(verify_results[idx_].strip()) == \"no\":\n",
    "            ans = reverse_ans(ans, pos_word, neg_word)\n",
    "        results.append(ans)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3586ba89-90e0-4518-ab99-6298d3b3ce7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_tweet_results_old(gpt_results, verify_results, pos_word, neg_word):\n",
    "    # def justify(string_):\n",
    "    #     if len(string_) >= 3 and string_[:3].lower() == \"yes\":\n",
    "    #         return \"yes\"\n",
    "    #     if len(string_) >= 2 and string_[:2].lower() == \"no\":\n",
    "    #         return \"no\"\n",
    "    #     return \"\"\n",
    "    def justify(string_):\n",
    "        if \"yes\" in string_.lower():\n",
    "            return \"yes\"\n",
    "        if \"no\" in string_.lower():\n",
    "            return \"no\"\n",
    "        return \"\"\n",
    "\n",
    "    def reverse_ans(string_, pos_word, neg_word):\n",
    "        if len(string_) >= 3 and pos_word in string_:\n",
    "            return string_.replace(pos_word, neg_word)\n",
    "        if len(string_) >= 2 and neg_word in string_:\n",
    "            return string_.replace(neg_word, pos_word)\n",
    "        return string_\n",
    "\n",
    "    results = []\n",
    "    for idx_, item in enumerate(gpt_results):\n",
    "        ans = \" \".join(item.strip().split())\n",
    "        if justify(verify_results[idx_].strip()) == \"no\":\n",
    "            ans = reverse_ans(ans, pos_word, neg_word)\n",
    "        results.append(ans)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "075255e4-50c9-4512-bcfc-7117eb732946",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.second.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a35d3383-c64b-4cc3-a022-051821bbcf33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.second.test.short.unbalanced.4.28.json\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\n"
     ]
    }
   ],
   "source": [
    "predictions = read_dialog_file(candidate_file)\n",
    "mrc_data = read_mrc_file(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "417f142d-5380-4ac0-8ff7-715e4e17b975",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.second.test.short.unbalanced.4.28.json\n"
     ]
    }
   ],
   "source": [
    "full_dialogs = read_full_dialog_file(candidate_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "42be96b4-cc94-4799-9f1b-8b0274a0ee04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Sure! Here's the labeled sentence with other entities associated with foodborne illnesses:\\n\\n@USER As much fun as I can . Woke up with <<food poisoning>> or stomach flu . Been bugging me all day #tmi Almost done driving for the day\\n\\nOther entities labeled in the sentence include:\\n\\n* food poisoning\\n* stomach flu\""
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_dialogs[3][-1]['generation']['content']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "904e18d6-f5fe-4869-adaa-71eb8b99437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_results(mrc_data, first_dialogs, label_symbol, type_count):\n",
    "    sym_len = len(label_symbol)\n",
    "    label_prefix, label_suffix = label_symbol[:sym_len // 2], label_symbol[sym_len // 2:]\n",
    "\n",
    "    def get_words(labeled_sentence, label_prefix, label_suffix):\n",
    "        word_list = []\n",
    "        words = labeled_sentence.strip().split()\n",
    "        flag = False\n",
    "        last_ = \"\"\n",
    "        for idx_, word in enumerate(words):\n",
    "            if len(word) > 2 and word[0] == label_prefix[0] and word[1] == label_prefix[1]:\n",
    "                last_ = idx_\n",
    "                flag = True\n",
    "            if flag and len(word) > 2 and word[-1] == label_suffix[-1] and word[-2] == label_suffix[-2]:\n",
    "                word_list.append((\" \".join(words[last_:idx_ + 1])[2:-2], last_, idx_))\n",
    "                flag = False\n",
    "        return word_list\n",
    "\n",
    "    merge_list = []\n",
    "    for item_idx in tqdm(range(len(mrc_data))):\n",
    "        item_ = mrc_data[item_idx]\n",
    "        sen_id, entity_id = [int(i) for i in item_[\"qas_id\"].split(\".\")]\n",
    "        if 0 == entity_id:\n",
    "            context = item_[\"context\"]\n",
    "            entity_label_dict = {}\n",
    "        origin_label = item_[\"entity_label\"]\n",
    "        entity_list = get_words(first_dialogs[sen_id - 1][-1]['generation']['content'].strip(), label_prefix,\n",
    "                                label_suffix)\n",
    "        entity_label_dict[origin_label] = entity_list\n",
    "        if type_count - 1 == entity_id:\n",
    "            previous_system = first_dialogs[sen_id - 1][0]\n",
    "            previous_assistant_response = first_dialogs[sen_id - 1][2]\n",
    "            merge_list.append({'context': context, \"entity_predictions\": entity_label_dict,\n",
    "                               'previous_system': previous_system,\n",
    "                               'previous_assistant_response': previous_assistant_response})\n",
    "    return merge_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e426a5c2-4091-432e-83e0-669885510f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648/1648 [00:00<00:00, 79482.70it/s]\n"
     ]
    }
   ],
   "source": [
    "merge_dialogs = merge_results(mrc_data, full_dialogs, \"<<>>\", 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "be065c31-2d13-4861-a5aa-26f95c513f07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': '@USER As much fun as I can . Woke up with food poisoning or stomach flu . Been bugging me all day #tmi Almost done driving for the day',\n",
       " 'entity_predictions': {'food': [], 'symptom': [], 'loc': [], 'other': []},\n",
       " 'previous_system': {'role': 'system',\n",
       "  'content': \"Always follow the user's instruction and only provide answer for the user's last given sentence\"},\n",
       " 'previous_assistant_response': {'role': 'assistant',\n",
       "  'content': \"Understood! I will only provide answer with formats like the user's instruction for the user's last given sentence.\"}}"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merge_dialogs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b535ee00-5bf4-41f4-9228-8aca56d27343",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"{'food': [], 'symptom': [], 'loc': [], 'other': []}\""
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(merge_dialogs[0]['entity_predictions'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "943b1da2-650f-400e-896e-6bd88f037ca1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     412\n",
      "unique      2\n",
      "top        No\n",
      "freq      207\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "last_example = [i[1]['content'].split(\": \")[-1][:-2] for i in full_dialogs]\n",
    "print(pd.Series(last_example).describe())\n",
    "final_answer = [i[4]['generation']['content'].split(\": \")[-1] for i in full_dialogs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "75d9927a-bdc4-4b03-af7e-6b0c6fa2962b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4368932038834951"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_list = [example.lower() in answer.lower() for example, answer in zip(last_example, final_answer)]\n",
    "np.mean(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ebf9639-3e75-4779-aedc-2770182021e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.6642335766423357,\n",
       "  0.40444444444444444,\n",
       "  0.5027624309392265,\n",
       "  0.5631067961165048),\n",
       " (141, 134, 46, 91))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6db34243-03e6-4fe8-a40e-e8b71e3261f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.first.test.short.unbalanced.4.28.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2b87a7cd-a988-4f54-b924-114659141e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.first.test.short.unbalanced.4.28.json\n"
     ]
    }
   ],
   "source": [
    "verify_results = read_dialog_file(verify_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9bf0cd0c-155c-4f66-a7fe-2dc14f20ac5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.first.test.short.unbalanced.4.28.json\n"
     ]
    }
   ],
   "source": [
    "full_verify_dialogs = read_full_dialog_file(verify_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "2e7567f6-7fbd-4709-a429-aea3c4f9ad26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count     412\n",
      "unique      2\n",
      "top        No\n",
      "freq      213\n",
      "dtype: object\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5315533980582524"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "last_example = [i[1]['content'].split(\": \")[-1][:-2] for i in full_verify_dialogs]\n",
    "print(pd.Series(last_example).describe())\n",
    "final_answer = [i[4]['generation']['content'].split(\": \")[-1] for i in full_verify_dialogs]\n",
    "match_list = [example.lower() in answer.lower() for example, answer in zip(last_example, final_answer)]\n",
    "np.mean(match_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e8cc1b68-33cc-49f7-9d3d-876b34dfe64f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.first.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "09c2a7b4-2578-41f5-9c42-6c0c6e094404",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.first.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [00:00, 1393591.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "final_results = read_openai_file(result_file)\n",
    "mrc_data = read_mrc_file(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e299646b-6df6-4d29-88ed-4fe5d63e40fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.7883211678832117,\n",
       "  0.36860068259385664,\n",
       "  0.5023255813953488,\n",
       "  0.48058252427184467),\n",
       " (90, 185, 29, 108))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data, final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "8f9a96a3-d63b-4ee7-bd68-c56839a87f3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.second.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0230866-8650-4a9f-b230-2e8a9141b864",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.second.test.short.unbalanced.4.28.json\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\n"
     ]
    }
   ],
   "source": [
    "predictions = read_dialog_file(candidate_file)\n",
    "mrc_data = read_mrc_file(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "577a89f1-5514-46c8-bf4c-360e77df2d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_file(labels, dir_, last_name):\n",
    "    print(\"writing ...\")\n",
    "    file_name = os.path.join(dir_, last_name)\n",
    "    file = open(file_name, \"w\")\n",
    "    for line in labels:\n",
    "        file.write(line.strip() + '\\n')\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "79668df1-fdb8-40a2-be58-a15f860998e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.32.knn.sequence.fullprompt.verified\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2808e1d1-dc01-46ec-98c6-a2cf55aea0ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "2842f507-9137-4b87-8f94-379de58956ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.test.short.unbalanced.4.28.json\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/mrc-ner.expert.test\n"
     ]
    }
   ],
   "source": [
    "predictions = read_dialog_file(candidate_file)\n",
    "mrc_data = read_mrc_file(reference_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "096e9692-d36d-4f71-8c98-e1ce585615f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "computting f1 ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.28343949044585987,\n",
       " 0.04777241009125067,\n",
       " 0.08176389526871843,\n",
       " {'tp': 89, 'fp': 1774, 'fn': 225},\n",
       " {'food': {'tp': 34, 'fp': 411, 'fn': 27},\n",
       "  'symptom': {'tp': 16, 'fp': 487, 'fn': 44},\n",
       "  'loc': {'tp': 27, 'fp': 428, 'fn': 26},\n",
       "  'other': {'tp': 12, 'fp': 448, 'fn': 128}})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_simple_f1(mrc_data=mrc_data, openai_data=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "02a08f76-0fba-4139-9693-3383c7e9d84b",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama-single/llama-2-13b-chat.verify.tc.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\"\n",
    "tmp_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama-single/llama-2-13b-chat.tmp.tc.test.short.unbalanced.4.28.json\"\n",
    "write_dir = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama-single/\"\n",
    "write_name = \"llama-2-13b-chat.tc.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "31625136-f1c3-4816-bde2-b06c01a71e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.reverse.second.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\"\n",
    "tmp_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.reverse.second.test.short.unbalanced.4.28.json\"\n",
    "write_dir = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/\"\n",
    "write_name = \"llama-2-13b-chat.reverse.second.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7ae19928-6757-41c7-8e11-7f54a3b18b86",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.reverse.2.second.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\"\n",
    "tmp_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.first.test.short.unbalanced.4.28.json\"\n",
    "write_dir = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/\"\n",
    "write_name = \"llama-2-13b-chat.reverse.2.second.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0ce74814-885f-43f2-9646-867884e4c40c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "verify_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.first.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\"\n",
    "tmp_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.first.test.short.unbalanced.4.28.json\"\n",
    "write_dir = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/\"\n",
    "write_name = \"llama-2-13b-chat.first.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "3f8e2648-e5e0-4433-911c-e8e5a318d11c",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.2.first.test.short.unbalanced.4.28.json\"\n",
    "reference_file = \"/scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\"\n",
    "tmp_candidate_file = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.reverse.second.test.short.unbalanced.4.28.json\"\n",
    "write_dir = \"/scratch/dzhang5/LLM/TWEET-FID/test-results-llama/\"\n",
    "write_name = \"llama-2-13b-chat.2.first.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "52f2b981-5628-4abb-9031-f90e3f31f3dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.tmp.reverse.second.test.short.unbalanced.4.28.json\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/mrc-tc.expert.test\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.verify.2.first.test.short.unbalanced.4.28.json\n",
      "read ... /scratch/dzhang5/LLM/TWEET-FID/test-results-llama/llama-2-13b-chat.2.first.short.unbalanced.4.28.32.knn.sequence.fullprompt.verified\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "412it [00:00, 295545.28it/s]\n"
     ]
    }
   ],
   "source": [
    "gpt_results = read_dialog_file(tmp_candidate_file)\n",
    "mrc_data = read_mrc_file(reference_file)\n",
    "verify_results = read_dialog_file(verify_candidate_file)\n",
    "previous_final_results = read_openai_file(os.path.join(write_dir, write_name))\n",
    "\n",
    "final_results = construct_tweet_results(gpt_results=gpt_results, verify_results=verify_results,\n",
    "                                            pos_word='yes', neg_word='no')\n",
    "\n",
    "final_results_old = construct_tweet_results_old(gpt_results=gpt_results, verify_results=verify_results,\n",
    "                                                pos_word='yes', neg_word='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "7fe82984-8af1-41a6-8d74-d67a5b77d3fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([i==j for i, j in zip(final_results_old, previous_final_results)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "0a4a9201-65bb-44f7-ab24-ad403aea2383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9197080291970803,\n",
       "  0.45161290322580644,\n",
       "  0.6057692307692307,\n",
       "  0.6019417475728155),\n",
       " (122, 153, 11, 126))"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data=mrc_data, openai_data=gpt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9be9a217-c695-474a-8e0d-7125884fec17",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.7956204379562044,\n",
       "  0.39636363636363636,\n",
       "  0.529126213592233,\n",
       "  0.529126213592233),\n",
       " (109, 166, 28, 109))"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data=mrc_data, openai_data=final_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "351aceee-0388-42a2-abc9-76a1bd41fd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.9708029197080292,\n",
       "  0.3481675392670157,\n",
       "  0.51252408477842,\n",
       "  0.3859223300970874),\n",
       " (26, 249, 4, 133))"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data=mrc_data, openai_data=final_results_old)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "5ce1cf73-6fdb-421d-b86c-654a17eced3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing ...\n"
     ]
    }
   ],
   "source": [
    "write_file(labels=final_results, dir_=write_dir, last_name=write_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "254a404b-84a9-4087-a93c-dacc8506de1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpt_predictions = [convert_label(_) for _ in gpt_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7f5e2655-690b-41d5-9cf5-217b7cee36ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [_['sentence_class'] for _ in mrc_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "feb25aed-d6c5-4948-8f4a-8cec2bb36165",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_labels = [int(i == j) for i, j in zip(gpt_predictions, labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e0401f90-bb50-40fb-800d-0f72d10e2723",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_predictions = [convert_label(_) for _ in verify_results]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6473061a-8724-4f0e-a6d2-c178300d0777",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_incorrect = [int(i!=j) for i, j in zip(verify_predictions, verify_labels)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b53d93f-0a6a-4796-bbc6-4b20428c6151",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_table = pd.DataFrame({'result': verify_results, 'label':verify_labels, 'pred':verify_predictions})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "35cd9261-774a-46f3-a40c-9fcd4b496621",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_results = construct_tweet_results(gpt_results=gpt_results, verify_results=verify_results,\n",
    "                                        pos_word='yes', neg_word='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e537671e-aeb9-40b9-88a6-f620b374ee9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def justify(string_):\n",
    "    if \"yes\" in string_.lower():\n",
    "        return \"yes\"\n",
    "    if \"no\" in string_.lower():\n",
    "        return \"no\"\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "71ad7474-bc21-409a-8e72-2cb4b7a81e9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    205\n",
       "no     198\n",
       "         9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([justify(_) for _ in gpt_results]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "b3c9e372-2d06-4438-8582-aed6e6840e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "no     290\n",
       "yes    119\n",
       "         3\n",
       "dtype: int64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([justify(_) for _ in verify_results]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f22b8ceb-1014-4da4-8f2f-3e3cf0ac2a83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "yes    296\n",
       "no     107\n",
       "         9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series([justify(_) for _ in final_results]).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c1723940-8ed1-4ab9-84fd-ba893a293b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.8467153284671532,\n",
       "  0.5658536585365853,\n",
       "  0.6783625730994152,\n",
       "  0.7330097087378641),\n",
       " (186, 89, 21, 116))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data, gpt_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "7756646d-c63f-44de-96e0-6a1af270800f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0.635036496350365,\n",
       "  0.2939189189189189,\n",
       "  0.4018475750577367,\n",
       "  0.3713592233009709),\n",
       " (66, 209, 50, 87))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compute_sentence_f1(mrc_data, final_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
