{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5198684-0eb5-4959-941e-59d467a9b688",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.train.short.csv'\n",
    "data_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.smalltest.csv'\n",
    "output_dir = '/scratch/dzhang5/LLM/TWEET-FID/test-results-autolabel'\n",
    "model_name = \"microsoft/phi-2\"\n",
    "label_column = 'sentence_class'\n",
    "text_column = 'tweet'\n",
    "few_shot_num = 8\n",
    "few_shot_selection = \"semantic_similarity\"\n",
    "token_path = \"/home/dzhang5/.cache/huggingface/token\"\n",
    "cache=False\n",
    "console_output=False\n",
    "temperature=0.1\n",
    "random_shuffle_examples = True\n",
    "random_shuffle_examples_seed = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "304c4a3a-04bc-4fd4-bb01-7b38f49f87cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel.schema import ModelProvider, TaskType\n",
    "from autolabel.models import register_model, MODEL_REGISTRY\n",
    "from hf_pipeline_new import HFPipelineLLMNew\n",
    "from few_shot_new import NewAutoLabelConfig, NewExampleSelectorFactory\n",
    "from autolabel.few_shot import ExampleSelectorFactory\n",
    "from template_inst import update_inst_mode\n",
    "from named_entity_recognition_new import NewNamedEntityRecognitionTask\n",
    "from classification_new import NewClassificationTask\n",
    "from autolabel.tasks import TASK_TYPE_TO_IMPLEMENTATION \n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38e6eb38-9d3f-4f9e-8889-aa9fe9121204",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_inst_mode(model_name)\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.NAMED_ENTITY_RECOGNITION] = NewNamedEntityRecognitionTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.CLASSIFICATION] = NewClassificationTask\n",
    "sys.modules['autolabel.labeler'].ExampleSelectorFactory = NewExampleSelectorFactory\n",
    "register_model(ModelProvider.HUGGINGFACE_PIPELINE, HFPipelineLLMNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d67c0a78-0a28-4ad1-84d2-9edf12534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent, AutolabelDataset\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b470589-0c67-4fc7-aba1-b0345eed23f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dzhang5/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open(token_path) as tfile:\n",
    "    token_str = tfile.read()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5043f6-302a-4c91-bc1c-547b760378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_auto = [\"microsoft/prophetnet\", \"microsoft/phi-2\", \"google/pegasus-x\"]\n",
    "if any([pre in model_name for pre in no_auto]):\n",
    "    device_map = None\n",
    "else:\n",
    "    device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed222805-4d26-48f9-8624-ad9ec57507c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuel_models = [\"refuel-llm\", \"llama-13b-chat\"]\n",
    "if model_name in refuel_models:\n",
    "    provider = \"refuel\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetClassificationQA_{few_shot_selection}_{model_name}\"\n",
    "elif model_name.startswith('gpt'):\n",
    "    provider = \"openai\"\n",
    "    em_provider = \"openai\"\n",
    "    model_params = {\"max_tokens\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetClassificationQA_{few_shot_selection}_{model_name}\"\n",
    "else:\n",
    "    provider = \"huggingface_pipeline\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature,\n",
    "                    \"quantize\": 16, \"device_map\": device_map,\n",
    "                    \"token\": token_str}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetClassificationQA_{few_shot_selection}_{model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ef8a6dd-7773-46be-8b94-695363657877",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(output_dir)\n",
    "output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "output_path = os.path.join(output_dir, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2ab5c16-a103-45e2-af9e-c31d98292779",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c5898aea-778b-4fed-8d89-519ed07f8f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "task_guideline = (\"You are an expert at identifying foodborne illness incident information. For the given text, \"\n",
    "                  \"your task is to evaluate the text to determine if it describes a potential foodborne illness event. \"\n",
    "                  '''Please answer with \"Yes\" if it describes a potential foodborne illness event, otherwise answer with \"No\".'''\n",
    "                  \"Use the following examples as a guide for your predictions and format your responses similarly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "15567ff5-37f7-4b35-a48b-83b310b410bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"task_name\": task_name,\n",
    "    \"task_type\": \"question_answering\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": label_column,\n",
    "        \"text_column\": text_column,\n",
    "        \"delimiter\": \",\"\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": provider,\n",
    "        \"name\": model_name,\n",
    "        \"params\": model_params\n",
    "    },\n",
    "    \"embedding\": {\n",
    "        \"provider\": em_provider,\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": task_guideline,\n",
    "        \"output_guidelines\": '''You will answer with just the correct output label (\"Yes\" or \"No\") and nothing else.''',\n",
    "        \"labels\": [\n",
    "            \"Yes\",\n",
    "            \"No\"\n",
    "        ],\n",
    "        \"few_shot_examples\": few_shot_path,\n",
    "        \"few_shot_selection\": few_shot_selection,\n",
    "        \"few_shot_num\": few_shot_num,\n",
    "        \"random_shuffle_examples\": random_shuffle_examples,\n",
    "        \"random_shuffle_examples_seed\": random_shuffle_examples_seed,\n",
    "        \"example_template\": f\"Input: {{{text_column}}}\\nOutput: {{{label_column}}}\"\n",
    "    }\n",
    "}\n",
    "\n",
    "config = NewAutoLabelConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e28122bc-1337-497b-8410-54fd17249452",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ff522a93a1427fb68ac66797291d61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/861 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b7afe3f4e9145b285f15ddd5c15c25c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb3b0b42f3a34ddaaf798d1da5233fcb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/phi-2 were not used when initializing PhiForCausalLM: ['model.layers.25.self_attn.k_proj.weight', 'model.layers.16.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.bias', 'model.layers.0.self_attn.k_proj.weight', 'model.layers.0.self_attn.q_proj.bias', 'model.layers.6.self_attn.k_proj.bias', 'model.layers.11.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.bias', 'model.layers.30.self_attn.q_proj.bias', 'model.layers.17.self_attn.k_proj.bias', 'model.layers.7.self_attn.q_proj.weight', 'model.layers.21.self_attn.k_proj.bias', 'model.layers.18.self_attn.q_proj.bias', 'model.layers.6.self_attn.q_proj.bias', 'model.layers.14.self_attn.v_proj.weight', 'model.layers.30.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.bias', 'model.layers.9.self_attn.k_proj.weight', 'model.layers.23.self_attn.q_proj.weight', 'model.layers.5.self_attn.k_proj.weight', 'model.layers.13.self_attn.k_proj.bias', 'model.layers.20.self_attn.k_proj.bias', 'model.layers.0.self_attn.v_proj.weight', 'model.layers.31.self_attn.v_proj.bias', 'model.layers.14.self_attn.v_proj.bias', 'model.layers.17.self_attn.v_proj.bias', 'model.layers.14.self_attn.k_proj.bias', 'model.layers.28.self_attn.k_proj.bias', 'model.layers.0.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.weight', 'model.layers.20.self_attn.q_proj.weight', 'model.layers.16.self_attn.q_proj.bias', 'model.layers.21.self_attn.v_proj.weight', 'model.layers.25.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.bias', 'model.layers.3.self_attn.k_proj.bias', 'model.layers.6.self_attn.q_proj.weight', 'model.layers.14.self_attn.q_proj.weight', 'model.layers.16.self_attn.v_proj.weight', 'model.layers.22.self_attn.q_proj.weight', 'model.layers.23.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.weight', 'model.layers.19.self_attn.q_proj.weight', 'model.layers.27.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.weight', 'model.layers.24.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.weight', 'model.layers.27.self_attn.q_proj.bias', 'model.layers.29.self_attn.q_proj.weight', 'model.layers.30.self_attn.v_proj.weight', 'model.layers.15.self_attn.v_proj.weight', 'model.layers.22.self_attn.v_proj.weight', 'model.layers.9.self_attn.v_proj.weight', 'model.layers.4.self_attn.v_proj.bias', 'model.layers.28.self_attn.v_proj.bias', 'model.layers.7.self_attn.k_proj.bias', 'model.layers.27.self_attn.v_proj.weight', 'model.layers.17.self_attn.k_proj.weight', 'model.layers.7.self_attn.q_proj.bias', 'model.layers.8.self_attn.v_proj.weight', 'model.layers.25.self_attn.v_proj.weight', 'model.layers.8.self_attn.k_proj.weight', 'model.layers.3.self_attn.k_proj.weight', 'model.layers.26.self_attn.v_proj.weight', 'model.layers.9.self_attn.k_proj.bias', 'model.layers.22.self_attn.v_proj.bias', 'model.layers.28.self_attn.q_proj.bias', 'model.layers.3.self_attn.v_proj.weight', 'model.layers.28.self_attn.q_proj.weight', 'model.layers.19.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.bias', 'model.layers.1.self_attn.v_proj.weight', 'model.layers.21.self_attn.q_proj.bias', 'model.layers.1.self_attn.k_proj.bias', 'model.layers.20.self_attn.v_proj.bias', 'model.layers.23.self_attn.v_proj.bias', 'model.layers.7.self_attn.v_proj.bias', 'model.layers.9.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.weight', 'model.layers.1.self_attn.k_proj.weight', 'model.layers.26.self_attn.k_proj.bias', 'model.layers.0.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.weight', 'model.layers.25.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.bias', 'model.layers.20.self_attn.v_proj.weight', 'model.layers.8.self_attn.v_proj.bias', 'model.layers.18.self_attn.v_proj.weight', 'model.layers.12.self_attn.k_proj.bias', 'model.layers.12.self_attn.q_proj.bias', 'model.layers.5.self_attn.v_proj.weight', 'model.layers.17.self_attn.q_proj.weight', 'model.layers.19.self_attn.v_proj.bias', 'model.layers.25.self_attn.k_proj.bias', 'model.layers.21.self_attn.q_proj.weight', 'model.layers.10.self_attn.k_proj.bias', 'model.layers.24.self_attn.k_proj.bias', 'model.layers.3.self_attn.q_proj.weight', 'model.layers.5.self_attn.q_proj.bias', 'model.layers.29.self_attn.k_proj.weight', 'model.layers.13.self_attn.q_proj.bias', 'model.layers.6.self_attn.v_proj.weight', 'model.layers.31.self_attn.q_proj.bias', 'model.layers.4.self_attn.q_proj.bias', 'model.layers.1.self_attn.q_proj.weight', 'model.layers.29.self_attn.v_proj.bias', 'model.layers.26.self_attn.q_proj.weight', 'model.layers.24.self_attn.v_proj.weight', 'model.layers.11.self_attn.q_proj.bias', 'model.layers.2.self_attn.v_proj.bias', 'model.layers.5.self_attn.q_proj.weight', 'model.layers.31.self_attn.k_proj.weight', 'model.layers.15.self_attn.k_proj.weight', 'model.layers.8.self_attn.q_proj.weight', 'model.layers.5.self_attn.v_proj.bias', 'model.layers.21.self_attn.v_proj.bias', 'model.layers.1.self_attn.v_proj.bias', 'model.layers.9.self_attn.v_proj.bias', 'model.layers.8.self_attn.k_proj.bias', 'model.layers.3.self_attn.v_proj.bias', 'model.layers.4.self_attn.k_proj.bias', 'model.layers.17.self_attn.q_proj.bias', 'model.layers.18.self_attn.k_proj.weight', 'model.layers.27.self_attn.k_proj.bias', 'model.layers.2.self_attn.v_proj.weight', 'model.layers.16.self_attn.v_proj.bias', 'model.layers.29.self_attn.k_proj.bias', 'model.layers.10.self_attn.v_proj.weight', 'model.layers.26.self_attn.v_proj.bias', 'model.layers.25.self_attn.q_proj.weight', 'model.layers.18.self_attn.v_proj.bias', 'model.layers.10.self_attn.k_proj.weight', 'model.layers.28.self_attn.v_proj.weight', 'model.layers.15.self_attn.q_proj.bias', 'model.layers.27.self_attn.q_proj.weight', 'model.layers.23.self_attn.k_proj.weight', 'model.layers.4.self_attn.v_proj.weight', 'model.layers.11.self_attn.k_proj.bias', 'model.layers.2.self_attn.q_proj.bias', 'model.layers.31.self_attn.k_proj.bias', 'model.layers.6.self_attn.k_proj.weight', 'model.layers.20.self_attn.k_proj.weight', 'model.layers.22.self_attn.q_proj.bias', 'model.layers.24.self_attn.v_proj.bias', 'model.layers.28.self_attn.k_proj.weight', 'model.layers.14.self_attn.k_proj.weight', 'model.layers.7.self_attn.k_proj.weight', 'model.layers.5.self_attn.k_proj.bias', 'model.layers.20.self_attn.q_proj.bias', 'model.layers.19.self_attn.k_proj.bias', 'model.layers.7.self_attn.v_proj.weight', 'model.layers.10.self_attn.q_proj.weight', 'model.layers.2.self_attn.k_proj.bias', 'model.layers.15.self_attn.v_proj.bias', 'model.layers.12.self_attn.v_proj.bias', 'model.layers.26.self_attn.k_proj.weight', 'model.layers.3.self_attn.q_proj.bias', 'model.layers.21.self_attn.k_proj.weight', 'model.layers.18.self_attn.k_proj.bias', 'model.layers.13.self_attn.v_proj.bias', 'model.layers.0.self_attn.v_proj.bias', 'model.layers.24.self_attn.k_proj.weight', 'model.layers.2.self_attn.k_proj.weight', 'model.layers.29.self_attn.v_proj.weight', 'model.layers.13.self_attn.v_proj.weight', 'model.layers.10.self_attn.v_proj.bias', 'model.layers.10.self_attn.q_proj.bias', 'model.layers.8.self_attn.q_proj.bias', 'model.layers.13.self_attn.k_proj.weight', 'model.layers.13.self_attn.q_proj.weight', 'model.layers.18.self_attn.q_proj.weight', 'model.layers.22.self_attn.k_proj.bias', 'model.layers.9.self_attn.q_proj.bias', 'model.layers.31.self_attn.q_proj.weight', 'model.layers.30.self_attn.k_proj.bias', 'model.layers.15.self_attn.q_proj.weight', 'model.layers.16.self_attn.k_proj.bias', 'model.layers.12.self_attn.v_proj.weight', 'model.layers.24.self_attn.q_proj.weight', 'model.layers.11.self_attn.v_proj.bias', 'model.layers.16.self_attn.q_proj.weight', 'model.layers.29.self_attn.q_proj.bias', 'model.layers.12.self_attn.k_proj.weight', 'model.layers.17.self_attn.v_proj.weight', 'model.layers.19.self_attn.v_proj.weight', 'model.layers.30.self_attn.v_proj.bias', 'model.layers.1.self_attn.q_proj.bias', 'model.layers.31.self_attn.v_proj.weight', 'model.layers.12.self_attn.q_proj.weight', 'model.layers.27.self_attn.k_proj.weight', 'model.layers.23.self_attn.q_proj.bias']\n",
      "- This IS expected if you are initializing PhiForCausalLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing PhiForCausalLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of PhiForCausalLM were not initialized from the model checkpoint at microsoft/phi-2 and are newly initialized: ['model.layers.20.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.bias', 'model.layers.4.self_attn.query_key_value.weight', 'model.layers.23.self_attn.query_key_value.weight', 'model.layers.18.self_attn.query_key_value.bias', 'model.layers.28.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.bias', 'model.layers.18.self_attn.query_key_value.weight', 'model.layers.14.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.weight', 'model.layers.30.self_attn.query_key_value.bias', 'model.layers.26.self_attn.query_key_value.weight', 'model.layers.3.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.bias', 'model.layers.25.self_attn.query_key_value.weight', 'model.layers.28.self_attn.query_key_value.bias', 'model.layers.3.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.weight', 'model.layers.21.self_attn.query_key_value.weight', 'model.layers.20.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.weight', 'model.layers.5.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.bias', 'model.layers.22.self_attn.query_key_value.bias', 'model.layers.21.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.weight', 'model.layers.9.self_attn.query_key_value.weight', 'model.layers.10.self_attn.query_key_value.weight', 'model.layers.6.self_attn.query_key_value.bias', 'model.layers.14.self_attn.query_key_value.bias', 'model.layers.23.self_attn.query_key_value.bias', 'model.layers.9.self_attn.query_key_value.bias', 'model.layers.2.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.weight', 'model.layers.26.self_attn.query_key_value.bias', 'model.layers.6.self_attn.query_key_value.weight', 'model.layers.27.self_attn.query_key_value.weight', 'model.layers.15.self_attn.query_key_value.bias', 'model.layers.19.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.bias', 'model.layers.8.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.weight', 'model.layers.13.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.weight', 'model.layers.7.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.weight', 'model.layers.29.self_attn.query_key_value.bias', 'model.layers.16.self_attn.query_key_value.bias', 'model.layers.12.self_attn.query_key_value.bias', 'model.layers.0.self_attn.query_key_value.weight', 'model.layers.17.self_attn.query_key_value.bias', 'model.layers.7.self_attn.query_key_value.weight', 'model.layers.2.self_attn.query_key_value.weight', 'model.layers.22.self_attn.query_key_value.weight', 'model.layers.1.self_attn.query_key_value.bias', 'model.layers.17.self_attn.query_key_value.weight', 'model.layers.4.self_attn.query_key_value.bias', 'model.layers.24.self_attn.query_key_value.bias', 'model.layers.30.self_attn.query_key_value.weight', 'model.layers.31.self_attn.query_key_value.bias', 'model.layers.11.self_attn.query_key_value.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "The model 'PhiForCausalLM' is not supported for text2text-generation. Supported models are ['BartForConditionalGeneration', 'BigBirdPegasusForConditionalGeneration', 'BlenderbotForConditionalGeneration', 'BlenderbotSmallForConditionalGeneration', 'EncoderDecoderModel', 'FSMTForConditionalGeneration', 'GPTSanJapaneseForConditionalGeneration', 'LEDForConditionalGeneration', 'LongT5ForConditionalGeneration', 'M2M100ForConditionalGeneration', 'MarianMTModel', 'MBartForConditionalGeneration', 'MT5ForConditionalGeneration', 'MvpForConditionalGeneration', 'NllbMoeForConditionalGeneration', 'PegasusForConditionalGeneration', 'PegasusXForConditionalGeneration', 'PLBartForConditionalGeneration', 'ProphetNetForConditionalGeneration', 'SeamlessM4TForTextToText', 'SeamlessM4Tv2ForTextToText', 'SwitchTransformersForConditionalGeneration', 'T5ForConditionalGeneration', 'UMT5ForConditionalGeneration', 'XLMProphetNetForConditionalGeneration'].\n"
     ]
    }
   ],
   "source": [
    "agent = LabelingAgent(config=config, console_output=console_output, cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c175c7c0-a61e-4d63-bc23-b06c51c8d72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-26 16:05:08 sentence_transformers.SentenceTransformer INFO: Load pretrained SentenceTransformer: sentence-transformers/all-mpnet-base-v2\n",
      "2024-01-26 16:05:09 sentence_transformers.SentenceTransformer INFO: Use pytorch device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a28f53797bcf4a7dbe606fa22ff7487c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d607694b15874c75b07b70153bd98343",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "592f448135ca4ffda9924eac120b46ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24a74901dd284d0c8cc7ca65e86c5b7e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7034391d53c54665b8eecd834cfeae3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a7df5a3d3325492aab0d79b0f9f1811d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "387f73e102bf4c87a87b574dec13c7dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4a1e394e64ca4a3db115dd22ea158418",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad018c581df94414b86595a9f3e0d646",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9518004676fa407cb034613fac6e1b6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9af774e1b8ca45739082783f0eb1fc70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "024922ab19ab4447a0e3b8805c5dc1d3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬──────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 10   </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0 </span>│\n",
       "└──────────────────────────┴──────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬──────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m10  \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴──────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at identifying foodborne illness incident information. Within the TWEET-FID dataset, the task is \n",
       "to evaluate a tweet in the TWEET-FID dataset to determine if it describes a potential foodborne illness event. \n",
       "Please answer with <span style=\"color: #008000; text-decoration-color: #008000\">'yes'</span> if it describes a potential foodborne illness event, otherwise answer with <span style=\"color: #008000; text-decoration-color: #008000\">'no'</span>.Use the \n",
       "following examples as a guide for your predictions and format your responses similarly.\n",
       "\n",
       "You will answer with just the correct output label <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">'yes'</span> or <span style=\"color: #008000; text-decoration-color: #008000\">'no'</span><span style=\"font-weight: bold\">)</span> and nothing else.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Input: @USER As much fun as I can. Woke up with food poisoning or stomach flu. Been bugging me all day #tmi Almost \n",
       "done driving for the day\n",
       "Output: yes\n",
       "\n",
       "Input: Today was rough. Think I had a touch of food poisoning earlier. Thought I was gonna die. Yuck. Therabreath \n",
       "rinse &amp; mints helped though! lol\n",
       "Output: yes\n",
       "\n",
       "Input: I cant come into work today because I have food poisoning. I went out with the lads last night and we had a \n",
       "cheap curry, we all ended up <span style=\"color: #808000; text-decoration-color: #808000\">...</span>\n",
       "Output: yes\n",
       "\n",
       "Input: @USER @USER that's not good, do you know what you ate to get food poisoning?\n",
       "Output: yes\n",
       "\n",
       "Input: I think I got food poison from ABW \n",
       "<span style=\"font-weight: bold\">[</span>EMOJI_astonished_face<span style=\"font-weight: bold\">][</span>EMOJI_face_with_medical_mask<span style=\"font-weight: bold\">][</span>EMOJI_face_screaming_in_fear<span style=\"font-weight: bold\">]</span>\n",
       "Output: yes\n",
       "\n",
       "Input: I think I have food poison poops &amp; vomit <span style=\"font-weight: bold\">[</span>EMOJI_persevering_face<span style=\"font-weight: bold\">]</span> that damn subway\n",
       "Output: yes\n",
       "\n",
       "Input: lmao RT @USER I've eaten off the streets in India &amp; Bhutan, nothing, on a cruise ship - food poisoning \n",
       "twice! #TNI #YouNeverKnow\n",
       "Output: yes\n",
       "\n",
       "Input: Food poisoning in Mandeville  HTTPURL\n",
       "Output: no\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Input: @USER As much fun as I can. Woke up with food poisoning or stomach flu. Been bugging me all day #tmi Almost \n",
       "done driving for the day\n",
       "Output: \n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at identifying foodborne illness incident information. Within the TWEET-FID dataset, the task is \n",
       "to evaluate a tweet in the TWEET-FID dataset to determine if it describes a potential foodborne illness event. \n",
       "Please answer with \u001b[32m'yes'\u001b[0m if it describes a potential foodborne illness event, otherwise answer with \u001b[32m'no'\u001b[0m.Use the \n",
       "following examples as a guide for your predictions and format your responses similarly.\n",
       "\n",
       "You will answer with just the correct output label \u001b[1m(\u001b[0m\u001b[32m'yes'\u001b[0m or \u001b[32m'no'\u001b[0m\u001b[1m)\u001b[0m and nothing else.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Input: @USER As much fun as I can. Woke up with food poisoning or stomach flu. Been bugging me all day #tmi Almost \n",
       "done driving for the day\n",
       "Output: yes\n",
       "\n",
       "Input: Today was rough. Think I had a touch of food poisoning earlier. Thought I was gonna die. Yuck. Therabreath \n",
       "rinse & mints helped though! lol\n",
       "Output: yes\n",
       "\n",
       "Input: I cant come into work today because I have food poisoning. I went out with the lads last night and we had a \n",
       "cheap curry, we all ended up \u001b[33m...\u001b[0m\n",
       "Output: yes\n",
       "\n",
       "Input: @USER @USER that's not good, do you know what you ate to get food poisoning?\n",
       "Output: yes\n",
       "\n",
       "Input: I think I got food poison from ABW \n",
       "\u001b[1m[\u001b[0mEMOJI_astonished_face\u001b[1m]\u001b[0m\u001b[1m[\u001b[0mEMOJI_face_with_medical_mask\u001b[1m]\u001b[0m\u001b[1m[\u001b[0mEMOJI_face_screaming_in_fear\u001b[1m]\u001b[0m\n",
       "Output: yes\n",
       "\n",
       "Input: I think I have food poison poops & vomit \u001b[1m[\u001b[0mEMOJI_persevering_face\u001b[1m]\u001b[0m that damn subway\n",
       "Output: yes\n",
       "\n",
       "Input: lmao RT @USER I've eaten off the streets in India & Bhutan, nothing, on a cruise ship - food poisoning \n",
       "twice! #TNI #YouNeverKnow\n",
       "Output: yes\n",
       "\n",
       "Input: Food poisoning in Mandeville  HTTPURL\n",
       "Output: no\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Input: @USER As much fun as I can. Woke up with food poisoning or stomach flu. Been bugging me all day #tmi Almost \n",
       "done driving for the day\n",
       "Output: \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ds = AutolabelDataset(test_data[[text_column, label_column]], config=config)\n",
    "agent.plan(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "066e6a3b-86ff-47ca-826a-e2690bfeee7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83d93439c7b1426f82dff64d03119ed0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8ab84c0a698405ea016c8d782a8dfcc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: \n",
       "UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in \n",
       "sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
       "  warnings.warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/transformers/generation/configuration_utils.py:389: \n",
       "UserWarning: `do_sample` is set to `False`. However, `temperature` is set to `0.9` -- this flag is only used in \n",
       "sample-based generation modes. You should set `do_sample=True` or unset `temperature`.\n",
       "  warnings.warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "This is a friendly reminder - the current text generation call will exceed the model's predefined maximum length (2048). Depending on the model, you may observe exceptions, performance degradation, or nothing at all.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "40aabaaee81e42dba9df047f1d8cef25",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20593adde16e4cbdbdb3a6e15bebce33",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "705a90f48dd54660a51180e2bf96a1bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches: 0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now, do the actual labeling\n",
    "ds = agent.run(ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7045720a-3e2a-432c-8f86-9d996e9a7980",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = ds.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bcbd487-91d5-44af-85e5-c85798e68704",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds.df.to_csv(output_path, index=False)\n",
    "ds.df.to_pickle(output_path.replace('.csv', '.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
