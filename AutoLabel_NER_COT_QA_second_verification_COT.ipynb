{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5198684-0eb5-4959-941e-59d467a9b688",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/1.0.expert.devfortrain.short.csv'\n",
    "data_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.traintestfortest.csv'\n",
    "output_dir = '/scratch/dzhang5/LLM/TWEET-FID/traintestfortest-results-autolabel-ner-qa-expert/0.1/1.0/lv_v1_tv_v1'\n",
    "tweet_output_dir = '/scratch/dzhang5/LLM/TWEET-FID/traintestfortest-results-autolabel-expert/0.1/1.0/lv_v1_tv_v1'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "label_column = 'Food_answer'\n",
    "text_column = 'context'\n",
    "explanation_column = 'Two_step_Food_explanation'\n",
    "example_selection_label_column = 'has_Food'\n",
    "label_symbol = \"^^^^\"\n",
    "few_shot_num = 8\n",
    "few_shot_selection = \"semantic_similarity\"\n",
    "verify_few_shot_selection = 'label_diversity_similarity'\n",
    "tweet_few_shot_selection = \"semantic_similarity\"\n",
    "second_verify_few_shot_selection = 'label_diversity_similarity'\n",
    "use_current_explanation = False\n",
    "use_ground_explanation = False\n",
    "token_path = \"/home/dzhang5/.cache/huggingface/token\"\n",
    "cache=False\n",
    "console_output=True\n",
    "temperature=0.1\n",
    "verify=True\n",
    "label_version='v1'\n",
    "task_version='v2'\n",
    "random_shuffle_examples = True\n",
    "random_shuffle_examples_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff44b7-dd3e-4e0a-abb4-aa59b62cd78a",
   "metadata": {},
   "source": [
    "# Generation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be56d66-8b3a-48f1-ba9b-5aea49f4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel.schema import ModelProvider, TaskType\n",
    "from autolabel.models import register_model, MODEL_REGISTRY\n",
    "from hf_pipeline_new import HFPipelineLLMNew\n",
    "from few_shot_new import NewAutoLabelConfig, NewExampleSelectorFactory\n",
    "from autolabel.few_shot import ExampleSelectorFactory\n",
    "from template_inst import update_inst_mode\n",
    "from named_entity_recognition_new import NewNamedEntityRecognitionTask\n",
    "from classification_new import NewClassificationTask\n",
    "from question_answering_new import NewQuestionAnsweringTask\n",
    "from autolabel.tasks import TASK_TYPE_TO_IMPLEMENTATION\n",
    "from prompt_template import load_ner_second_verify_task_prompt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bc6fcd-7a0f-4e12-9116-4879e308abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_inst_mode(model_name)\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.NAMED_ENTITY_RECOGNITION] = NewNamedEntityRecognitionTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.CLASSIFICATION] = NewClassificationTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.QUESTION_ANSWERING] = NewQuestionAnsweringTask\n",
    "sys.modules['autolabel.labeler'].ExampleSelectorFactory = NewExampleSelectorFactory\n",
    "register_model(ModelProvider.HUGGINGFACE_PIPELINE, HFPipelineLLMNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67c0a78-0a28-4ad1-84d2-9edf12534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent, AutolabelDataset\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d69efda-a796-4ba8-9b7a-a43bc10db380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dzhang5/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open(token_path) as tfile:\n",
    "    token_str = tfile.read()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5043f6-302a-4c91-bc1c-547b760378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_auto = [\"microsoft/prophetnet\", \"microsoft/phi-2\", \"google/pegasus-x\"]\n",
    "if any([pre in model_name for pre in no_auto]):\n",
    "    device_map = None\n",
    "else:\n",
    "    device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292533f9-7851-4717-ade0-0f1ab70dfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(output_dir)\n",
    "label_type = label_column.split('_')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b708a997-e78c-4f18-8178-797ad95b6bea",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_name = '_aggregated_final_COT_'\n",
    "if explanation_column.startswith('Two_step'):\n",
    "    explanation_column_str = 'two_step'\n",
    "else:\n",
    "    explanation_column_str = 'one_step'\n",
    "if few_shot_selection != verify_few_shot_selection:\n",
    "    final_name = final_name + verify_few_shot_selection + '_'\n",
    "agg_output_name = os.path.split(model_name)[-1] + '_strict_' + few_shot_selection + '_COT_' + str(explanation_column_str) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + final_name + os.path.split(data_path)[-1]\n",
    "agg_output_path = os.path.join(output_dir, agg_output_name)\n",
    "agg_output_data = pd.read_csv(agg_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11d08659-8803-467d-8971-2948827c98c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_output_name = os.path.split(model_name)[-1] + '_' + tweet_few_shot_selection + '_COT_check_' + agg_output_name\n",
    "tweet_output_path = os.path.join(tweet_output_dir, tweet_output_name)\n",
    "tweet_output_data = pd.read_csv(tweet_output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a00bc18-8124-4baf-8c6b-65bb9b63482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuel_models = [\"refuel-llm\", \"llama-13b-chat\"]\n",
    "if model_name in refuel_models:\n",
    "    provider = \"refuel\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "elif model_name.startswith('gpt'):\n",
    "    provider = \"openai\"\n",
    "    em_provider = \"openai\"\n",
    "    model_params = {\"max_tokens\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "else:\n",
    "    provider = \"huggingface_pipeline\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature,\n",
    "                    \"quantize\": 16, \"device_map\": device_map,\n",
    "                    \"token\": token_str}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24584382-9105-4e3b-933d-82647a77d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_len = len(label_symbol)\n",
    "label_prefix, label_suffix, label_description, verify_task_guideline, verify_output_guideline = load_ner_second_verify_task_prompt(label_type, label_symbol, label_version, task_version, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "24db5348-dfef-4597-b09c-8d6d6947553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e32dd-03c5-4b1c-bab3-cdcaf4f5ccf0",
   "metadata": {},
   "source": [
    "# Verification Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3107cb00-b025-4ac2-9974-ff9c7febaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_word_second_verification_refer_ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc9f434c-5a06-492d-a6d4-e792a810bd7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_few_shot_data = pd.read_csv(few_shot_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "620ea1cf-edcd-4571-b933-9ab481996026",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_sen_reference_column = 'second_sentence_verify_reference'\n",
    "verify_word_reference_column = f'{label_type}_second_verify_reference'\n",
    "verify_explanation_column = f'{label_type}_second_verify_explanation'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "060654db-729b-4058-92ce-fbf919beb319",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_few_shot_data[[verify_sen_reference_column, verify_word_reference_column, verify_explanation_column]] = \\\n",
    "verify_few_shot_data[['CategorizedLabels', 'sentence_class']].apply(lambda x: generate_word_second_verification_refer_ans(x['CategorizedLabels'], label_type, x['sentence_class']), axis=1, result_type='expand')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e9afc92d-046d-45ad-8a3f-8b3746d14266",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_few_shot_data.to_csv(few_shot_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ca64179-0f5d-47d1-8331-fb4a4f9c1150",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (agg_output_data[text_column] == tweet_output_data[text_column]).all()\n",
    "assert (agg_output_data.index == tweet_output_data.index).all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7ca23057-7af7-48c4-9218-145c38893e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = agg_output_data[[text_column, 'CategorizedLabels_prediction', label_column]].copy()\n",
    "new_test_data['sentence_class_label'] = tweet_output_data['sentence_class_label']\n",
    "new_test_data[[verify_sen_reference_column, verify_word_reference_column, '_']] = \\\n",
    "new_test_data[['CategorizedLabels_prediction', 'sentence_class_label']].apply(lambda x: generate_word_second_verification_refer_ans(x['CategorizedLabels_prediction'], label_type, x['sentence_class_label']), axis=1, result_type='expand')\n",
    "new_test_data.drop(columns=['CategorizedLabels_prediction', 'sentence_class_label', '_'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f299170c-dee7-4663-9c69-ba5ba1310e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_final_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + label_type + '_second_final_COT_' + second_verify_few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "output_final_path = os.path.join(output_dir, output_final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a28d97b0-87b4-40b7-bc43-7135e3cbe7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"task_name\": task_name+'_second_verification',\n",
    "    \"task_type\": \"question_answering\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": label_column,\n",
    "        \"text_column\": text_column,\n",
    "        \"explanation_column\": verify_explanation_column,\n",
    "        \"example_selection_label_column\": example_selection_label_column,\n",
    "        \"delimiter\": \",\",\n",
    "        \"label_description\": label_description\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": provider,\n",
    "        \"name\": model_name,\n",
    "        \"params\": model_params\n",
    "    },\n",
    "    \"embedding\": {\n",
    "        \"provider\": em_provider,\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": verify_task_guideline,\n",
    "        \"output_guidelines\": verify_output_guideline,\n",
    "        \"example_selection_labels\":[\n",
    "            \"yes\",\n",
    "            \"no\"\n",
    "        ],\n",
    "        \"few_shot_examples\": few_shot_path,\n",
    "        \"few_shot_selection\": second_verify_few_shot_selection,\n",
    "        \"few_shot_num\": few_shot_num,\n",
    "        \"random_shuffle_examples\": random_shuffle_examples,\n",
    "        \"random_shuffle_examples_seed\": random_shuffle_examples_seed,\n",
    "        \"example_template\": f\"Context: {{{text_column}}}\\nFinding: 1. {{{verify_sen_reference_column}}}\\n2. {{{verify_word_reference_column}}}\\nAnswer: Let's think step by step.\\n{{{verify_explanation_column}}}\\n{{{label_column}}}\",\n",
    "        \"chain_of_thought\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "config = NewAutoLabelConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "27e8d888-20f0-4e12-9dbd-f52ca407b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 01:20:11 autolabel.labeler WARNING: cache parameter is deprecated and will be removed soon. Please use generation_cache and transform_cache instead.\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = LabelingAgent(config=config, console_output=console_output, cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "92763312-ebaa-48b2-9d85-546c37558f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds = AutolabelDataset(new_test_data, config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ad700d3-2a4e-4738-872b-c3fd8e13667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-04-09 01:20:14 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "823772017e044d7796341bedc9773b6b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-09 01:20:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:16 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:17 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:18 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:19 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:19 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:19 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:19 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:20 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:21 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:22 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:23 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:24 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:25 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:26 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:27 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:28 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:29 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:30 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:31 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:32 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:34 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:34 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:34 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-04-09 01:20:34 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $38.462 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 3710    </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0104 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$38.462\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m3710   \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0104\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at extracting Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to label Food entities that are specific food item that caused the potential foodborne \n",
       "illness incident. If a Food entity does not cause a potential foodborne illness incident, the entity should not be \n",
       "labeled as relevant entities.Another model has determine whether the text indicates a foodborne illness incident or\n",
       "not, you can take it as a reference. But the finding might be incorrect.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct labeled sentence. In the last line of the \n",
       "response, you should present the input text with Food entities related to foodborne illness incidents distinctly \n",
       "marked. To highlight these Food entities, prepend each with <span style=\"color: #008000; text-decoration-color: #008000\">\"^^\"</span> and append <span style=\"color: #008000; text-decoration-color: #008000\">\"^^\"</span>. Refer to the provided examples to\n",
       "structure your predictions correctly.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: I'm not sending this my stomach again . . . . I'm wearing these fire outfits <span style=\"font-weight: bold\">[</span> \n",
       "EMOJI_smiling_face_with_heart-eyes <span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span> EMOJI_smiling_face_with_heart-eyes <span style=\"font-weight: bold\">]</span>\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text does not indicate a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I'm not sending this my stomach again . . . . I'm wearing these fire outfits [ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EMOJI_smiling_face_with_heart-eyes ] [ EMOJI_smiling_face_with_heart-eyes ]\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: Germ inflicted grapes and food poisoning <span style=\"font-weight: bold\">[</span> EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span> EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span> \n",
       "EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span> HTTPURL\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text indicates a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The word <span style=\"color: #008000; text-decoration-color: #008000\">\"grapes\"</span> in the text is a Food entity, which is a specific food item that caused the potential \n",
       "foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word <span style=\"color: #008000; text-decoration-color: #008000\">\"grapes\"</span> in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Germ inflicted ^^grapes^^ and food poisoning [ EMOJI_loudly_crying_face ] [ EMOJI_loudly_crying_face ] [</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EMOJI_loudly_crying_face ] HTTPURL\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: Really hope I don't have a stomach bug or food poisoning <span style=\"font-weight: bold\">[</span> EMOJI_disappointed_face <span style=\"font-weight: bold\">]</span>\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text does not indicate a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Really hope I don't have a stomach bug or food poisoning [ EMOJI_disappointed_face ]\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: The last time I had sushi I got food poisoning and it hurts me because I enjoy sushi so much <span style=\"font-weight: bold\">[</span> \n",
       "EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span> I also need a turmeric latte or I might die\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text indicates a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The words <span style=\"color: #008000; text-decoration-color: #008000\">\"sushi\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"sushi\"</span> in the text are Food entities, which are specific food items that caused the \n",
       "potential foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the words <span style=\"color: #008000; text-decoration-color: #008000\">\"sushi\"</span> and <span style=\"color: #008000; text-decoration-color: #008000\">\"sushi\"</span> in \n",
       "the text are Food entities, which are specific food items that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"The last time I had ^^sushi^^ I got food poisoning and it hurts me because I enjoy ^^sushi^^ so much [ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EMOJI_loudly_crying_face ] I also need a turmeric latte or I might die\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: @USER It is ! I gave myself food poisoning when I was learning to cook . Pro living tip : cook your shrimp\n",
       "fully <span style=\"font-weight: bold\">[</span> EMOJI_shrimp <span style=\"font-weight: bold\">]</span>\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text indicates a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The word <span style=\"color: #008000; text-decoration-color: #008000\">\"shrimp\"</span> in the text is a Food entity, which is a specific food item that caused the potential \n",
       "foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word <span style=\"color: #008000; text-decoration-color: #008000\">\"shrimp\"</span> in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"@USER It is ! I gave myself food poisoning when I was learning to cook . Pro living tip : cook your </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">^^shrimp^^ fully [ EMOJI_shrimp ]\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: I'm fina punch my stomach so hard <span style=\"font-weight: bold\">[</span> EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span> Bc why tf is it hurting .\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text does not indicate a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I'm fina punch my stomach so hard [ EMOJI_loudly_crying_face ] Bc why tf is it hurting .\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: I know damn well beans upset my stomach and what I do ? ? ?\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text indicates a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. The word <span style=\"color: #008000; text-decoration-color: #008000\">\"beans\"</span> in the text is a Food entity, which is a specific food item that caused the potential foodborne\n",
       "illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word <span style=\"color: #008000; text-decoration-color: #008000\">\"beans\"</span> in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"I know damn well ^^beans^^ upset my stomach and what I do ? ? ?\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Context: You ever tell someone you not hungry cuz u dont want they food then ur stomach starts growling <span style=\"font-weight: bold\">[</span> \n",
       "EMOJI_woozy_face <span style=\"font-weight: bold\">]</span>\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text does not indicate a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"You ever tell someone you not hungry cuz u dont want they food then ur stomach starts growling [ </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">EMOJI_woozy_face ]\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: I know my tubes tied but When Mother Nature be playing I give my stomach a extra punch just in case cause \n",
       "bitch don't play with me <span style=\"font-weight: bold\">[</span> EMOJI_face_with_raised_eyebrow <span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span> EMOJI_unamused_face <span style=\"font-weight: bold\">]</span> <span style=\"font-weight: bold\">[</span> EMOJI_loudly_crying_face <span style=\"font-weight: bold\">]</span>\n",
       "Finding: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>. The text does not indicate a foodborne illness incident.\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span>. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at extracting Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to label Food entities that are specific food item that caused the potential foodborne \n",
       "illness incident. If a Food entity does not cause a potential foodborne illness incident, the entity should not be \n",
       "labeled as relevant entities.Another model has determine whether the text indicates a foodborne illness incident or\n",
       "not, you can take it as a reference. But the finding might be incorrect.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct labeled sentence. In the last line of the \n",
       "response, you should present the input text with Food entities related to foodborne illness incidents distinctly \n",
       "marked. To highlight these Food entities, prepend each with \u001b[32m\"^^\"\u001b[0m and append \u001b[32m\"^^\"\u001b[0m. Refer to the provided examples to\n",
       "structure your predictions correctly.\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: I'm not sending this my stomach again . . . . I'm wearing these fire outfits \u001b[1m[\u001b[0m \n",
       "EMOJI_smiling_face_with_heart-eyes \u001b[1m]\u001b[0m \u001b[1m[\u001b[0m EMOJI_smiling_face_with_heart-eyes \u001b[1m]\u001b[0m\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text does not indicate a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"I'm not sending this my stomach again . . . . I'm wearing these fire outfits \u001b[0m\u001b[32m[\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mEMOJI_smiling_face_with_heart-eyes \u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_smiling_face_with_heart-eyes \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: Germ inflicted grapes and food poisoning \u001b[1m[\u001b[0m EMOJI_loudly_crying_face \u001b[1m]\u001b[0m \u001b[1m[\u001b[0m EMOJI_loudly_crying_face \u001b[1m]\u001b[0m \u001b[1m[\u001b[0m \n",
       "EMOJI_loudly_crying_face \u001b[1m]\u001b[0m HTTPURL\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text indicates a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. The word \u001b[32m\"grapes\"\u001b[0m in the text is a Food entity, which is a specific food item that caused the potential \n",
       "foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word \u001b[32m\"grapes\"\u001b[0m in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Germ inflicted ^^grapes^^ and food poisoning \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_loudly_crying_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_loudly_crying_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m \u001b[0m\u001b[32m[\u001b[0m\n",
       "\u001b[32mEMOJI_loudly_crying_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m HTTPURL\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: Really hope I don't have a stomach bug or food poisoning \u001b[1m[\u001b[0m EMOJI_disappointed_face \u001b[1m]\u001b[0m\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text does not indicate a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Really hope I don't have a stomach bug or food poisoning \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_disappointed_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: The last time I had sushi I got food poisoning and it hurts me because I enjoy sushi so much \u001b[1m[\u001b[0m \n",
       "EMOJI_loudly_crying_face \u001b[1m]\u001b[0m I also need a turmeric latte or I might die\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text indicates a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. The words \u001b[32m\"sushi\"\u001b[0m and \u001b[32m\"sushi\"\u001b[0m in the text are Food entities, which are specific food items that caused the \n",
       "potential foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the words \u001b[32m\"sushi\"\u001b[0m and \u001b[32m\"sushi\"\u001b[0m in \n",
       "the text are Food entities, which are specific food items that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"The last time I had ^^sushi^^ I got food poisoning and it hurts me because I enjoy ^^sushi^^ so much \u001b[0m\u001b[32m[\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mEMOJI_loudly_crying_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m I also need a turmeric latte or I might die\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: @USER It is ! I gave myself food poisoning when I was learning to cook . Pro living tip : cook your shrimp\n",
       "fully \u001b[1m[\u001b[0m EMOJI_shrimp \u001b[1m]\u001b[0m\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text indicates a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. The word \u001b[32m\"shrimp\"\u001b[0m in the text is a Food entity, which is a specific food item that caused the potential \n",
       "foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word \u001b[32m\"shrimp\"\u001b[0m in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"@USER It is ! I gave myself food poisoning when I was learning to cook . Pro living tip : cook your \u001b[0m\n",
       "\u001b[32m^^shrimp^^ fully \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_shrimp \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: I'm fina punch my stomach so hard \u001b[1m[\u001b[0m EMOJI_loudly_crying_face \u001b[1m]\u001b[0m Bc why tf is it hurting .\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text does not indicate a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"I'm fina punch my stomach so hard \u001b[0m\u001b[32m[\u001b[0m\u001b[32m EMOJI_loudly_crying_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m Bc why tf is it hurting .\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: I know damn well beans upset my stomach and what I do ? ? ?\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text indicates a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. The word \u001b[32m\"beans\"\u001b[0m in the text is a Food entity, which is a specific food item that caused the potential foodborne\n",
       "illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text indicates a foodborne illness incident. Also, the word \u001b[32m\"beans\"\u001b[0m in the text is a \n",
       "Food entity, which is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"I know damn well ^^beans^^ upset my stomach and what I do ? ? ?\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Context: You ever tell someone you not hungry cuz u dont want they food then ur stomach starts growling \u001b[1m[\u001b[0m \n",
       "EMOJI_woozy_face \u001b[1m]\u001b[0m\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text does not indicate a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "As the finding suggests, the text does not indicate a foodborne illness incident. Hence, no Food entity in the text\n",
       "is related to foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"You ever tell someone you not hungry cuz u dont want they food then ur stomach starts growling \u001b[0m\u001b[32m[\u001b[0m\u001b[32m \u001b[0m\n",
       "\u001b[32mEMOJI_woozy_face \u001b[0m\u001b[32m]\u001b[0m\u001b[32m\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: I know my tubes tied but When Mother Nature be playing I give my stomach a extra punch just in case cause \n",
       "bitch don't play with me \u001b[1m[\u001b[0m EMOJI_face_with_raised_eyebrow \u001b[1m]\u001b[0m \u001b[1m[\u001b[0m EMOJI_unamused_face \u001b[1m]\u001b[0m \u001b[1m[\u001b[0m EMOJI_loudly_crying_face \u001b[1m]\u001b[0m\n",
       "Finding: \u001b[1;36m1\u001b[0m. The text does not indicate a foodborne illness incident.\n",
       "\u001b[1;36m2\u001b[0m. No Food entity in the text is relevant to foodborne illness incident.\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.plan(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6839c9-9ddb-45c5-a719-7853f8b9fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, do the actual labeling\n",
    "verify_ds = agent.run(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59777587-3757-4d4b-9a6e-46922b1b555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = verify_ds.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba58de-265c-4ec5-9e22-ba2497e09257",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds.df.to_csv(output_final_path, index=False)\n",
    "verify_ds.df.to_pickle(output_final_path.replace('.csv', '.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
