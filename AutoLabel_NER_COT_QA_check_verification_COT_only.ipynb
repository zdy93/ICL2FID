{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5198684-0eb5-4959-941e-59d467a9b688",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.train.short.csv'\n",
    "verify_few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/Food-verify.expert.train.short.csv'\n",
    "data_path = '/scratch/dzhang5/LLM/TWEET-FID/traintestfortest-results-autolabel-expert/0.1/1.0/gpt-3.5-turbo_semantic_similarity_COT__cur_False_ground_False_final_COT_label_diversity_similarity_expert.traintestfortest.csv'\n",
    "ori_data_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.traintestfortest.csv'\n",
    "output_dir = '/scratch/dzhang5/LLM/TWEET-FID/traintestfortest-results-autolabel-ner-qa-expert/0.1/1.0/lv_v1_tv_v1'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "label_column = 'Food_answer'\n",
    "text_column = 'context'\n",
    "explanation_column = 'Food_explanation'\n",
    "reference_column = 'word_check_reference'\n",
    "example_selection_label_column = 'Food_check_class'\n",
    "label_symbol = \"^^^^\"\n",
    "few_shot_num = 8\n",
    "few_shot_selection = 'semantic_similarity'\n",
    "verify_few_shot_selection = 'label_diversity_similarity'\n",
    "token_path = \"/home/dzhang5/.cache/huggingface/token\"\n",
    "cache=False\n",
    "console_output=True\n",
    "temperature=0.1\n",
    "verify=True\n",
    "label_version='v1'\n",
    "task_version='v1'\n",
    "random_shuffle_examples = True\n",
    "random_shuffle_examples_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff44b7-dd3e-4e0a-abb4-aa59b62cd78a",
   "metadata": {},
   "source": [
    "# Generation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be56d66-8b3a-48f1-ba9b-5aea49f4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel.schema import ModelProvider, TaskType\n",
    "from autolabel.models import register_model, MODEL_REGISTRY\n",
    "from hf_pipeline_new import HFPipelineLLMNew\n",
    "from few_shot_new import NewAutoLabelConfig, NewExampleSelectorFactory\n",
    "from autolabel.few_shot import ExampleSelectorFactory\n",
    "from template_inst import update_inst_mode\n",
    "from named_entity_recognition_new import NewNamedEntityRecognitionTask\n",
    "from classification_new import NewClassificationTask\n",
    "from question_answering_new import NewQuestionAnsweringTask\n",
    "from autolabel.tasks import TASK_TYPE_TO_IMPLEMENTATION\n",
    "from prompt_template import load_ner_check_task_prompt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bc6fcd-7a0f-4e12-9116-4879e308abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_inst_mode(model_name)\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.NAMED_ENTITY_RECOGNITION] = NewNamedEntityRecognitionTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.CLASSIFICATION] = NewClassificationTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.QUESTION_ANSWERING] = NewQuestionAnsweringTask\n",
    "sys.modules['autolabel.labeler'].ExampleSelectorFactory = NewExampleSelectorFactory\n",
    "register_model(ModelProvider.HUGGINGFACE_PIPELINE, HFPipelineLLMNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67c0a78-0a28-4ad1-84d2-9edf12534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent, AutolabelDataset\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d69efda-a796-4ba8-9b7a-a43bc10db380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dzhang5/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open(token_path) as tfile:\n",
    "    token_str = tfile.read()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5043f6-302a-4c91-bc1c-547b760378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_auto = [\"microsoft/prophetnet\", \"microsoft/phi-2\", \"google/pegasus-x\"]\n",
    "if any([pre in model_name for pre in no_auto]):\n",
    "    device_map = None\n",
    "else:\n",
    "    device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292533f9-7851-4717-ade0-0f1ab70dfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(output_dir)\n",
    "label_type = label_column.split('_')[0]\n",
    "output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_check_' + '_' + label_type + '_' + os.path.split(data_path)[-1]\n",
    "output_path = os.path.join(output_dir, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a00bc18-8124-4baf-8c6b-65bb9b63482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuel_models = [\"refuel-llm\", \"llama-13b-chat\"]\n",
    "if model_name in refuel_models:\n",
    "    provider = \"refuel\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "elif model_name.startswith('gpt'):\n",
    "    provider = \"openai\"\n",
    "    em_provider = \"openai\"\n",
    "    model_params = {\"max_tokens\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "else:\n",
    "    provider = \"huggingface_pipeline\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature,\n",
    "                    \"quantize\": 16, \"device_map\": device_map,\n",
    "                    \"token\": token_str}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERQA_{few_shot_selection}_{label_type}_{model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24584382-9105-4e3b-933d-82647a77d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_len = len(label_symbol)\n",
    "label_prefix, label_suffix, label_description, task_guideline, output_guideline = load_ner_check_task_prompt(label_type, label_symbol, label_version, task_version, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd318b49-e846-495f-85ae-846f41a31907",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import generate_word_check_ref_ans, generate_word_explanation_prediction\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24db5348-dfef-4597-b09c-8d6d6947553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path)\n",
    "ori_test_data = pd.read_csv(ori_data_path)\n",
    "\n",
    "assert (test_data[text_column] == ori_test_data[text_column]).all()\n",
    "\n",
    "if label_column not in test_data.columns:\n",
    "    test_data[label_column] = ori_test_data[label_column]\n",
    "\n",
    "if reference_column not in test_data.columns:\n",
    "    test_data[reference_column] = test_data['sentence_class_label'].apply(generate_word_explanation_prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e32dd-03c5-4b1c-bab3-cdcaf4f5ccf0",
   "metadata": {},
   "source": [
    "# Verification Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "271c2784-92eb-46be-a72a-a115e21927a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_results = pd.read_csv(output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3107cb00-b025-4ac2-9974-ff9c7febaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_predictions, check_prediction, get_verify_df, construct_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "620ea1cf-edcd-4571-b933-9ab481996026",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_question_column = f'{label_type}_verify_question'\n",
    "verify_answer_column = f'{label_type}_verify_answer'\n",
    "verify_explanation_column = f'{label_type}_verify_explanation'\n",
    "pos_column = f'{label_column}_pos'\n",
    "verify_example_selection_label_column = f'has_{label_type}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8556623a-3c8e-4efc-8adf-882360d5aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[[verify_question_column, pos_column]] = last_results[[f'{label_column}_label']].apply(lambda x: get_predictions(x[f'{label_column}_label'], label_symbol), axis=1,result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28274a9b-c585-4c3a-948e-9282f140e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if 'CategorizedLabels' not in test_data.columns:\n",
    "    test_data['CategorizedLabels'] = ori_test_data['CategorizedLabels']\n",
    "test_data[verify_answer_column] = test_data[['CategorizedLabels', verify_question_column]].apply(lambda x: check_prediction(x['CategorizedLabels'], x[verify_question_column], label_type), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1b9fcf33-04ac-4ccf-b39d-e6b3b9cae196",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = get_verify_df(test_data, verify_question_column, verify_answer_column, text_column, pos_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f39e79a1-8832-48fe-95c8-5ebb1a0efb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_task_guideline = (f\"You are an expert at identifying {label_type} entities that are related to foodborne illness incident from text. \" \n",
    "                         f\"In the given text, your task is to verify if a given word is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')} in the given text. \"\n",
    "                         \"Use the following examples as a guide for your analysis and format your responses similarly.\")\n",
    "question = f'''Do you think the word \"{{{verify_question_column}}}\" in the given text is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')}?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f299170c-dee7-4663-9c69-ba5ba1310e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verify_few_shot_selection == few_shot_selection:\n",
    "    output_verify_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_check_' + '_' + label_type + '_verify_COT_' + os.path.split(data_path)[-1]\n",
    "    output_verify_path = os.path.join(output_dir, output_verify_name)\n",
    "    output_final_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_check_' + '_' + label_type + '_final_COT_' + os.path.split(data_path)[-1]\n",
    "else:\n",
    "    output_verify_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_check_' + '_' + label_type + '_verify_COT_' + verify_few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "    output_verify_path = os.path.join(output_dir, output_verify_name)\n",
    "    output_final_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_check_' + '_' + label_type + '_final_COT_' + verify_few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "output_final_path = os.path.join(output_dir, output_final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a28d97b0-87b4-40b7-bc43-7135e3cbe7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"task_name\": task_name+'_verification',\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": verify_answer_column,\n",
    "        \"text_column\": text_column,\n",
    "        \"explanation_column\": verify_explanation_column,\n",
    "        \"example_selection_label_column\": verify_example_selection_label_column,\n",
    "        \"delimiter\": \",\",\n",
    "        \"label_description\": label_description\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": provider,\n",
    "        \"name\": model_name,\n",
    "        \"params\": model_params\n",
    "    },\n",
    "    \"embedding\": {\n",
    "        \"provider\": em_provider,\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": verify_task_guideline,\n",
    "        \"output_guidelines\": ('''Your answer will consist of an explanation, followed by the correct answer (\"Yes\" or \"No\").'''\n",
    "                              f'''Please answer with \"Yes\" if the given word is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')} in the given text, otherwise answer with \"No\".'''\n",
    "                              '''The last line of the response should always be JSON format with one key: {\"label\": \"the correct answer\"}.\\n'''\n",
    "                             ),\n",
    "        \"labels\": [\n",
    "            \"Yes\",\n",
    "            \"No\"\n",
    "        ],\n",
    "        \"example_selection_labels\":[\n",
    "            \"yes\",\n",
    "            \"no\"\n",
    "        ],\n",
    "        \"few_shot_examples\": verify_few_shot_path,\n",
    "        \"few_shot_selection\": verify_few_shot_selection,\n",
    "        \"few_shot_num\": few_shot_num,\n",
    "        \"random_shuffle_examples\": random_shuffle_examples,\n",
    "        \"random_shuffle_examples_seed\": random_shuffle_examples_seed,\n",
    "        \"example_template\": f\"Context: {{{text_column}}}\\nQuestion: {question}\\nAnswer: Let's think step by step.\\n{{{verify_explanation_column}}}\\n{{{verify_answer_column}}}\",\n",
    "        \"chain_of_thought\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "config = NewAutoLabelConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "27e8d888-20f0-4e12-9dbd-f52ca407b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 19:39:30 autolabel.labeler WARNING: cache parameter is deprecated and will be removed soon. Please use generation_cache and transform_cache instead.\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = LabelingAgent(config=config, console_output=console_output, cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "92763312-ebaa-48b2-9d85-546c37558f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds = AutolabelDataset(new_test_data.drop(['text_idx',pos_column], axis=1), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2ad700d3-2a4e-4738-872b-c3fd8e13667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-03-31 19:39:33 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:38 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:42 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b45b219d3daf4958b3d7f51720b5f1ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-31 19:39:44 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:45 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:46 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:46 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:46 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:46 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:47 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:48 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:49 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:49 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:49 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:49 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:50 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:51 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:52 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:52 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:52 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:53 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:53 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:53 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:55 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:55 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:55 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:58 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:58 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:58 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:39:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:00 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:01 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:01 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:01 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:03 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:04 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:05 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:05 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:05 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:05 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:05 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:06 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:06 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:06 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:06 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:08 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:09 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:09 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:09 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:10 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:10 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-31 19:40:10 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $9.9449 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 1018    </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0098 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$9.9449\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m1018   \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0098\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at identifying Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to verify if a given word is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident in the given text. Use the following examples as a guide for your analysis and\n",
       "format your responses similarly.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct answer <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span> or <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">)</span>.Please answer with <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span>\n",
       "if the given word is a Food entity that is specific food item that caused the potential foodborne illness incident \n",
       "in the given text, otherwise answer with <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span>.The last line of the response should always be JSON format with one \n",
       "key: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"the correct answer\"</span><span style=\"font-weight: bold\">}</span>.\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: Food poisoning from this weekend still fucking w/ me smh <span style=\"font-weight: bold\">[</span> EMOJI_weary_face <span style=\"font-weight: bold\">]</span>\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"poisoning from\"</span> in the given text is a Food entity that is specific food item that\n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"poisoning from\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: @USER @USER @USER LOL DONT GET FOOD POISONING ! Me and my friend both got a taco in a bag on Tuesday and \n",
       "we were both extremely sick the next morning\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"taco\"</span> in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"taco\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: I wish this Food Poison shit would go away !\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"!\"</span> in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"!\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: Food poison , hate that school lunch\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"school lunch\"</span> in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"school lunch\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: one time ruel made me a quesadilla and it gave me food poisoning . #ruelisoverparty\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"quesadilla\"</span> in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"quesadilla\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: S/O to Juannita's for some DOPE Little <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> food poisoning ! ! ! ! Talk about the ILLEST college weekend , \n",
       "amirite ? !\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"? !\"</span> in the given text is a Food entity that is specific food item that caused the\n",
       "potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"? !\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: Got food poisoning from school food . <span style=\"font-weight: bold\">[</span> EMOJI_face_with_medical_mask <span style=\"font-weight: bold\">]</span>\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"school food\"</span> in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"school food\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: Boyyyy oh boy . This like that time I got food poisoning at the most inopportune of possible times .\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"at the\"</span> in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"at the\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: S/O to Juannita's for some DOPE Little <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> food poisoning ! ! ! ! Talk about the ILLEST college weekend , \n",
       "amirite ? !\n",
       "Question: Do you think the word <span style=\"color: #008000; text-decoration-color: #008000\">\"Juannita's\"</span> in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at identifying Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to verify if a given word is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident in the given text. Use the following examples as a guide for your analysis and\n",
       "format your responses similarly.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct answer \u001b[1m(\u001b[0m\u001b[32m\"Yes\"\u001b[0m or \u001b[32m\"No\"\u001b[0m\u001b[1m)\u001b[0m.Please answer with \u001b[32m\"Yes\"\u001b[0m\n",
       "if the given word is a Food entity that is specific food item that caused the potential foodborne illness incident \n",
       "in the given text, otherwise answer with \u001b[32m\"No\"\u001b[0m.The last line of the response should always be JSON format with one \n",
       "key: \u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"the correct answer\"\u001b[0m\u001b[1m}\u001b[0m.\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: Food poisoning from this weekend still fucking w/ me smh \u001b[1m[\u001b[0m EMOJI_weary_face \u001b[1m]\u001b[0m\n",
       "Question: Do you think the word \u001b[32m\"poisoning from\"\u001b[0m in the given text is a Food entity that is specific food item that\n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"poisoning from\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: @USER @USER @USER LOL DONT GET FOOD POISONING ! Me and my friend both got a taco in a bag on Tuesday and \n",
       "we were both extremely sick the next morning\n",
       "Question: Do you think the word \u001b[32m\"taco\"\u001b[0m in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"taco\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: I wish this Food Poison shit would go away !\n",
       "Question: Do you think the word \u001b[32m\"!\"\u001b[0m in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"!\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: Food poison , hate that school lunch\n",
       "Question: Do you think the word \u001b[32m\"school lunch\"\u001b[0m in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"school lunch\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: one time ruel made me a quesadilla and it gave me food poisoning . #ruelisoverparty\n",
       "Question: Do you think the word \u001b[32m\"quesadilla\"\u001b[0m in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"quesadilla\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: S/O to Juannita's for some DOPE Little \u001b[1;36m5\u001b[0m food poisoning ! ! ! ! Talk about the ILLEST college weekend , \n",
       "amirite ? !\n",
       "Question: Do you think the word \u001b[32m\"? !\"\u001b[0m in the given text is a Food entity that is specific food item that caused the\n",
       "potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"? !\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: Got food poisoning from school food . \u001b[1m[\u001b[0m EMOJI_face_with_medical_mask \u001b[1m]\u001b[0m\n",
       "Question: Do you think the word \u001b[32m\"school food\"\u001b[0m in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"school food\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: Boyyyy oh boy . This like that time I got food poisoning at the most inopportune of possible times .\n",
       "Question: Do you think the word \u001b[32m\"at the\"\u001b[0m in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"at the\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: S/O to Juannita's for some DOPE Little \u001b[1;36m5\u001b[0m food poisoning ! ! ! ! Talk about the ILLEST college weekend , \n",
       "amirite ? !\n",
       "Question: Do you think the word \u001b[32m\"Juannita's\"\u001b[0m in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident?\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.plan(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd6839c9-9ddb-45c5-a719-7853f8b9fd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now, do the actual labeling\n",
    "verify_ds = agent.run(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59777587-3757-4d4b-9a6e-46922b1b555c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = verify_ds.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130d151-0d22-4156-a456-0b52d897efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data[f'{verify_answer_column}_label'] = verify_ds.df[f'{verify_answer_column}_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288fcfb-7934-434a-aa70-2c03e51b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds.df['text_idx'] = new_test_data['text_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba58de-265c-4ec5-9e22-ba2497e09257",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds.df.to_csv(output_verify_path, index=False)\n",
    "verify_ds.df.to_pickle(output_verify_path.replace('.csv', '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77168401-84f4-4c23-a4cc-3ca9613cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = construct_results(last_results, new_test_data, f'{label_column}_label', f'{verify_answer_column}_label', \"text_idx\", pos_column, label_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f40a09-e1e0-4781-85fb-63d91caf9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result.to_csv(output_final_path, index=False)\n",
    "new_result.to_pickle(output_final_path.replace('.csv', '.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
