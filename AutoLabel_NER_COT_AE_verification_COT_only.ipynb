{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f5198684-0eb5-4959-941e-59d467a9b688",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.train.short.csv'\n",
    "verify_few_shot_path = '/scratch/dzhang5/LLM/TWEET-FID/Food-verify.expert.train.short.csv'\n",
    "data_path = '/scratch/dzhang5/LLM/TWEET-FID/expert.smalltest.csv'\n",
    "output_dir = '/scratch/dzhang5/LLM/TWEET-FID/test-results-autolabel-ner-qa'\n",
    "model_name = \"gpt-3.5-turbo\"\n",
    "label_column = 'Food_answer'\n",
    "text_column = 'context'\n",
    "explanation_column = 'Food_explanation'\n",
    "example_selection_label_column = 'has_Food'\n",
    "label_symbol = \"^^^^\"\n",
    "few_shot_num = 8\n",
    "few_shot_selection = 'label_diversity_similarity'\n",
    "verify_few_shot_selection = \"semantic_similarity\"\n",
    "use_current_explanation = False\n",
    "use_ground_explanation = False\n",
    "token_path = \"/home/dzhang5/.cache/huggingface/token\"\n",
    "cache=False\n",
    "console_output=True\n",
    "temperature=0.1\n",
    "verify=True\n",
    "label_version='v1'\n",
    "task_version='v2'\n",
    "random_shuffle_examples = True\n",
    "random_shuffle_examples_seed = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bff44b7-dd3e-4e0a-abb4-aa59b62cd78a",
   "metadata": {},
   "source": [
    "# Generation Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7be56d66-8b3a-48f1-ba9b-5aea49f4b4e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel.schema import ModelProvider, TaskType\n",
    "from autolabel.models import register_model, MODEL_REGISTRY\n",
    "from hf_pipeline_new import HFPipelineLLMNew\n",
    "from few_shot_new import NewAutoLabelConfig, NewExampleSelectorFactory\n",
    "from autolabel.few_shot import ExampleSelectorFactory\n",
    "from template_inst import update_inst_mode\n",
    "from named_entity_recognition_new import NewNamedEntityRecognitionTask\n",
    "from classification_new import NewClassificationTask\n",
    "from question_answering_new import NewQuestionAnsweringTask\n",
    "from attribute_extraction_new import NewAttributeExtractionTask\n",
    "from autolabel.tasks import TASK_TYPE_TO_IMPLEMENTATION\n",
    "from prompt_template import load_ner_ae_prompt\n",
    "from dataset_new import process_labels\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "30bc6fcd-7a0f-4e12-9116-4879e308abd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "update_inst_mode(model_name)\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.NAMED_ENTITY_RECOGNITION] = NewNamedEntityRecognitionTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.CLASSIFICATION] = NewClassificationTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.QUESTION_ANSWERING] = NewQuestionAnsweringTask\n",
    "TASK_TYPE_TO_IMPLEMENTATION[TaskType.ATTRIBUTE_EXTRACTION] = NewAttributeExtractionTask\n",
    "sys.modules['autolabel.labeler'].ExampleSelectorFactory = NewExampleSelectorFactory\n",
    "sys.modules['autolabel.dataset'].AutolabelDataset.process_labels = process_labels\n",
    "register_model(ModelProvider.HUGGINGFACE_PIPELINE, HFPipelineLLMNew)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d67c0a78-0a28-4ad1-84d2-9edf12534aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from autolabel import LabelingAgent, AutolabelDataset\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0d69efda-a796-4ba8-9b7a-a43bc10db380",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Token will not been saved to git credential helper. Pass `add_to_git_credential=True` if you want to set the git credential as well.\n",
      "Token is valid (permission: read).\n",
      "Your token has been saved to /home/dzhang5/.cache/huggingface/token\n",
      "Login successful\n"
     ]
    }
   ],
   "source": [
    "with open(token_path) as tfile:\n",
    "    token_str = tfile.read()\n",
    "\n",
    "from huggingface_hub import login\n",
    "login(token=token_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae5043f6-302a-4c91-bc1c-547b760378ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_auto = [\"microsoft/prophetnet\", \"microsoft/phi-2\", \"google/pegasus-x\"]\n",
    "if any([pre in model_name for pre in no_auto]):\n",
    "    device_map = None\n",
    "else:\n",
    "    device_map = \"auto\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "292533f9-7851-4717-ade0-0f1ab70dfebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_type = label_column.split('_')[0]\n",
    "if not os.path.exists(output_dir):\n",
    "    # Create the directory\n",
    "    os.makedirs(output_dir)\n",
    "output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_AE_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + os.path.split(data_path)[-1]\n",
    "output_path = os.path.join(output_dir, output_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a00bc18-8124-4baf-8c6b-65bb9b63482a",
   "metadata": {},
   "outputs": [],
   "source": [
    "refuel_models = [\"refuel-llm\", \"llama-13b-chat\"]\n",
    "if model_name in refuel_models:\n",
    "    provider = \"refuel\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERAE_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "elif model_name.startswith('gpt'):\n",
    "    provider = \"openai\"\n",
    "    em_provider = \"openai\"\n",
    "    model_params = {\"max_tokens\":4096, \"temperature\": temperature}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERAE_{few_shot_selection}_{label_type}_{model_name}\"\n",
    "else:\n",
    "    provider = \"huggingface_pipeline\"\n",
    "    em_provider = \"huggingface_pipeline\"\n",
    "    model_params = {\"max_length\":4096, \"temperature\": temperature,\n",
    "                    \"quantize\": 16, \"device_map\": device_map,\n",
    "                    \"token\": token_str}\n",
    "    task_name = f\"FoodborneIllnessIncidentTweetNERAE_{few_shot_selection}_{label_type}_{model_name.split('/')[1]}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24584382-9105-4e3b-933d-82647a77d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "sym_len = len(label_symbol)\n",
    "label_prefix, label_suffix, label_description, task_guideline, output_guideline = load_ner_ae_prompt(label_symbol, label_version, task_version, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24db5348-dfef-4597-b09c-8d6d6947553c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(data_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e32dd-03c5-4b1c-bab3-cdcaf4f5ccf0",
   "metadata": {},
   "source": [
    "# Verification Stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "271c2784-92eb-46be-a72a-a115e21927a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "last_results = pd.read_csv(output_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3107cb00-b025-4ac2-9974-ff9c7febaab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import get_predictions, check_prediction, get_verify_df, construct_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "620ea1cf-edcd-4571-b933-9ab481996026",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_question_column = f'{label_type}_verify_question'\n",
    "verify_answer_column = f'{label_type}_verify_answer'\n",
    "verify_explanation_column = f'{label_type}_verify_explanation'\n",
    "pos_column = f'{label_column}_pos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8556623a-3c8e-4efc-8adf-882360d5aecb",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[[verify_question_column, pos_column]] = last_results[[f'{label_column}_label']].apply(lambda x: get_predictions(x[f'{label_column}_label'], label_symbol), axis=1,result_type=\"expand\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "28274a9b-c585-4c3a-948e-9282f140e82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[verify_answer_column] = test_data[['CategorizedLabels', verify_question_column]].apply(lambda x: check_prediction(x['CategorizedLabels'], x[verify_question_column], label_type), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b9fcf33-04ac-4ccf-b39d-e6b3b9cae196",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data = get_verify_df(test_data, verify_question_column, verify_answer_column, text_column, pos_column)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f39e79a1-8832-48fe-95c8-5ebb1a0efb89",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_task_guideline = (f\"You are an expert at identifying {label_type} entities that are related to foodborne illness incident from text. \" \n",
    "                         f\"In the given text, your task is to verify if a given word is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')} in the given text. \"\n",
    "                         \"Use the following examples as a guide for your analysis and format your responses similarly.\")\n",
    "question = f'''Do you think the word \"{{{verify_question_column}}}\" in the given text is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')}?'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f299170c-dee7-4663-9c69-ba5ba1310e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "if verify_few_shot_selection == few_shot_selection:\n",
    "    output_verify_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_AE_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + label_type + '_verify_COT_' + os.path.split(data_path)[-1]\n",
    "    output_verify_path = os.path.join(output_dir, output_verify_name)\n",
    "    output_final_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_AE_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + label_type + '_final_COT_' + os.path.split(data_path)[-1]\n",
    "else:\n",
    "    output_verify_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_AE_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + label_type + '_verify_COT_' + verify_few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "    output_verify_path = os.path.join(output_dir, output_verify_name)\n",
    "    output_final_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_AE_' + str(explanation_column) + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + label_type + '_final_COT_' + verify_few_shot_selection + '_' + os.path.split(data_path)[-1]\n",
    "output_final_path = os.path.join(output_dir, output_final_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a28d97b0-87b4-40b7-bc43-7135e3cbe7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"task_name\": task_name+'_verification',\n",
    "    \"task_type\": \"classification\",\n",
    "    \"dataset\": {\n",
    "        \"label_column\": verify_answer_column,\n",
    "        \"text_column\": text_column,\n",
    "        \"explanation_column\": verify_explanation_column,\n",
    "        \"example_selection_label_column\": example_selection_label_column,\n",
    "        \"delimiter\": \",\",\n",
    "        \"label_description\": label_description\n",
    "    },\n",
    "    \"model\": {\n",
    "        \"provider\": provider,\n",
    "        \"name\": model_name,\n",
    "        \"params\": model_params\n",
    "    },\n",
    "    \"embedding\": {\n",
    "        \"provider\": em_provider,\n",
    "    },\n",
    "    \"prompt\": {\n",
    "        \"task_guidelines\": verify_task_guideline,\n",
    "        \"output_guidelines\": ('''Your answer will consist of an explanation, followed by the correct answer (\"Yes\" or \"No\").'''\n",
    "                              f'''Please answer with \"Yes\" if the given word is a {label_type} entity that {label_description[label_type].replace('are ', 'is ').replace('.', '')} in the given text, otherwise answer with \"No\".'''\n",
    "                              '''The last line of the response should always be JSON format with one key: {\"label\": \"the correct answer\"}.\\n'''\n",
    "                             ),\n",
    "        \"labels\": [\n",
    "            \"Yes\",\n",
    "            \"No\"\n",
    "        ],\n",
    "        \"example_selection_labels\":[\n",
    "            \"yes\",\n",
    "            \"no\"\n",
    "        ],\n",
    "        \"few_shot_examples\": verify_few_shot_path,\n",
    "        \"few_shot_selection\": verify_few_shot_selection,\n",
    "        \"few_shot_num\": few_shot_num,\n",
    "        \"use_current_explanation\": use_current_explanation,\n",
    "        \"random_shuffle_examples\": random_shuffle_examples,\n",
    "        \"random_shuffle_examples_seed\": random_shuffle_examples_seed,\n",
    "        \"example_template\": f\"Context: {{{text_column}}}\\nQuestion: {question}\\nAnswer: Let's think step by step.\\n{{{verify_explanation_column}}}\\n{{{verify_answer_column}}}\",\n",
    "        \"chain_of_thought\": True\n",
    "    }\n",
    "}\n",
    "\n",
    "config = NewAutoLabelConfig(config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "27e8d888-20f0-4e12-9dbd-f52ca407b1ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:54:59 autolabel.labeler WARNING: cache parameter is deprecated and will be removed soon. Please use generation_cache and transform_cache instead.\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "agent = LabelingAgent(config=config, console_output=console_output, cache=cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "92763312-ebaa-48b2-9d85-546c37558f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds = AutolabelDataset(new_test_data.drop(['text_idx',pos_column], axis=1), config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2ad700d3-2a4e-4738-872b-c3fd8e13667f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n",
      "2024-03-20 23:55:02 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:07 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:11 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aa0c6ade30544069a3f4f0678b0f3173",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:55:14 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:14 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:14 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:55:15 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┌──────────────────────────┬─────────┐\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Total Estimated Cost     </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0681 </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Number of Examples       </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> 7       </span>│\n",
       "│<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Average cost per example </span>│<span style=\"color: #008000; text-decoration-color: #008000; font-weight: bold\"> $0.0097 </span>│\n",
       "└──────────────────────────┴─────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┌──────────────────────────┬─────────┐\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mTotal Estimated Cost    \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0681\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mNumber of Examples      \u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m7      \u001b[0m\u001b[1;32m \u001b[0m│\n",
       "│\u001b[1;35m \u001b[0m\u001b[1;35mAverage cost per example\u001b[0m\u001b[1;35m \u001b[0m│\u001b[1;32m \u001b[0m\u001b[1;32m$0.0097\u001b[0m\u001b[1;32m \u001b[0m│\n",
       "└──────────────────────────┴─────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────── </span>Prompt Example<span style=\"color: #00ff00; text-decoration-color: #00ff00\"> ──────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────── \u001b[0mPrompt Example\u001b[92m ──────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">You are an expert at identifying Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to verify if a given word is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident. in the given text. Use the following examples as a guide for your analysis \n",
       "and format your responses similarly.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct answer <span style=\"font-weight: bold\">(</span><span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span> or <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">)</span>.Please answer with <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span>\n",
       "if the given word is a Food entity that is specific food item that caused the potential foodborne illness incident.\n",
       "in the given text, otherwise answer with <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span>.The last line of the response should always be JSON format with one \n",
       "key: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"the correct answer\"</span><span style=\"font-weight: bold\">}</span>.\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: I am either dying or have food poisoning . . . I'm going with food poisoning since I cooked meat today <span style=\"font-weight: bold\">[</span> \n",
       "EMOJI_face_with_medical_mask <span style=\"font-weight: bold\">]</span>\n",
       "Question: Do you think the word meat in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"meat\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: @USER Sure its food poisoning ? Really bad stomach flu going around the whole country . Feels like food \n",
       "poisoning .\n",
       "Question: Do you think the word poisoning ? Really in the given text is a Food entity that is specific food item \n",
       "that caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"poisoning ? Really\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: Think I might have gotten a mild case of food-poisoning today - so that's been super fun .\n",
       "Question: Do you think the word gotten in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"gotten\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: @USER LOL I know ! I've had a stomach bug or food poisoning since yesterday afternoon\n",
       "Question: Do you think the word stomach bug or in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"stomach bug or\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: @USER @USER @USER LOL DONT GET FOOD POISONING ! Me and my friend both got a taco in a bag on Tuesday and \n",
       "we were both extremely sick the next morning\n",
       "Question: Do you think the word taco in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"taco\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: I've had food poisoning all day and I'm just miserable\n",
       "Question: Do you think the word I've had food in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"I've had food\"</span> does not cause a potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"No\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: @USER @USER I ate wing fries and got food poisoning bro . I do not wish this feeling upon anyone . I've \n",
       "been peeing out my ass for the past <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">12</span> hours or so\n",
       "Question: Do you think the word wing fries in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"wing fries\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "Context: All that free food yesterday made me SO sick <span style=\"font-weight: bold\">[</span> EMOJI_face_with_tears_of_joy <span style=\"font-weight: bold\">]</span> idk if I got a bit of food \n",
       "poisoning or if a random <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span> hour bug suddenly came on , but WOW it was intense !\n",
       "Question: Do you think the word free food in the given text is a Food entity that is specific food item that caused\n",
       "the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word <span style=\"color: #008000; text-decoration-color: #008000\">\"free food\"</span> is a specific food item that caused the potential foodborne illness incident.\n",
       "<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">\"label\"</span>: <span style=\"color: #008000; text-decoration-color: #008000\">\"Yes\"</span><span style=\"font-weight: bold\">}</span>\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: @USER As much fun as I can . Woke up with food poisoning or stomach flu . Been bugging me all day #tmi \n",
       "Almost done driving for the day\n",
       "Question: Do you think the word food poisoning in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "You are an expert at identifying Food entities that are related to foodborne illness incident from text. In the \n",
       "given text, your task is to verify if a given word is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident. in the given text. Use the following examples as a guide for your analysis \n",
       "and format your responses similarly.\n",
       "\n",
       "Your answer will consist of an explanation, followed by the correct answer \u001b[1m(\u001b[0m\u001b[32m\"Yes\"\u001b[0m or \u001b[32m\"No\"\u001b[0m\u001b[1m)\u001b[0m.Please answer with \u001b[32m\"Yes\"\u001b[0m\n",
       "if the given word is a Food entity that is specific food item that caused the potential foodborne illness incident.\n",
       "in the given text, otherwise answer with \u001b[32m\"No\"\u001b[0m.The last line of the response should always be JSON format with one \n",
       "key: \u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"the correct answer\"\u001b[0m\u001b[1m}\u001b[0m.\n",
       "\n",
       "\n",
       "Some examples with their output answers are provided below:\n",
       "\n",
       "Context: I am either dying or have food poisoning . . . I'm going with food poisoning since I cooked meat today \u001b[1m[\u001b[0m \n",
       "EMOJI_face_with_medical_mask \u001b[1m]\u001b[0m\n",
       "Question: Do you think the word meat in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"meat\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: @USER Sure its food poisoning ? Really bad stomach flu going around the whole country . Feels like food \n",
       "poisoning .\n",
       "Question: Do you think the word poisoning ? Really in the given text is a Food entity that is specific food item \n",
       "that caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"poisoning ? Really\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: Think I might have gotten a mild case of food-poisoning today - so that's been super fun .\n",
       "Question: Do you think the word gotten in the given text is a Food entity that is specific food item that caused \n",
       "the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"gotten\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: @USER LOL I know ! I've had a stomach bug or food poisoning since yesterday afternoon\n",
       "Question: Do you think the word stomach bug or in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"stomach bug or\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: @USER @USER @USER LOL DONT GET FOOD POISONING ! Me and my friend both got a taco in a bag on Tuesday and \n",
       "we were both extremely sick the next morning\n",
       "Question: Do you think the word taco in the given text is a Food entity that is specific food item that caused the \n",
       "potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"taco\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: I've had food poisoning all day and I'm just miserable\n",
       "Question: Do you think the word I've had food in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"I've had food\"\u001b[0m does not cause a potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"No\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: @USER @USER I ate wing fries and got food poisoning bro . I do not wish this feeling upon anyone . I've \n",
       "been peeing out my ass for the past \u001b[1;36m12\u001b[0m hours or so\n",
       "Question: Do you think the word wing fries in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"wing fries\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "Context: All that free food yesterday made me SO sick \u001b[1m[\u001b[0m EMOJI_face_with_tears_of_joy \u001b[1m]\u001b[0m idk if I got a bit of food \n",
       "poisoning or if a random \u001b[1;36m24\u001b[0m hour bug suddenly came on , but WOW it was intense !\n",
       "Question: Do you think the word free food in the given text is a Food entity that is specific food item that caused\n",
       "the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "The word \u001b[32m\"free food\"\u001b[0m is a specific food item that caused the potential foodborne illness incident.\n",
       "\u001b[1m{\u001b[0m\u001b[32m\"label\"\u001b[0m: \u001b[32m\"Yes\"\u001b[0m\u001b[1m}\u001b[0m\n",
       "\n",
       "Now I want you to label the following example:\n",
       "Context: @USER As much fun as I can . Woke up with food poisoning or stomach flu . Been bugging me all day #tmi \n",
       "Almost done driving for the day\n",
       "Question: Do you think the word food poisoning in the given text is a Food entity that is specific food item that \n",
       "caused the potential foodborne illness incident.?\n",
       "Answer: Let's think step by step.\n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #00ff00; text-decoration-color: #00ff00\">───────────────────────────────────────────────────────────────────────────────────────────────────────────────────</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[92m───────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "agent.plan(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cd6839c9-9ddb-45c5-a719-7853f8b9fd1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "35686d581dc745e09929d20fb1249f1f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-03-20 23:45:53 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:54 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:55 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:55 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:56 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:57 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:58 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:58 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "2024-03-20 23:45:59 httpx INFO: HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">classification_report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "          No       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.57</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.73</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "         Yes       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "\n",
       "    accuracy                           <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.57</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "   macro avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.50</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.29</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.36</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "weighted avg       <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.00</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.57</span>      <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.73</span>         <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">7</span>\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "classification_report:\n",
       "              precision    recall  f1-score   support\n",
       "\n",
       "          No       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.57\u001b[0m      \u001b[1;36m0.73\u001b[0m         \u001b[1;36m7\u001b[0m\n",
       "         Yes       \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m      \u001b[1;36m0.00\u001b[0m         \u001b[1;36m0\u001b[0m\n",
       "\n",
       "    accuracy                           \u001b[1;36m0.57\u001b[0m         \u001b[1;36m7\u001b[0m\n",
       "   macro avg       \u001b[1;36m0.50\u001b[0m      \u001b[1;36m0.29\u001b[0m      \u001b[1;36m0.36\u001b[0m         \u001b[1;36m7\u001b[0m\n",
       "weighted avg       \u001b[1;36m1.00\u001b[0m      \u001b[1;36m0.57\u001b[0m      \u001b[1;36m0.73\u001b[0m         \u001b[1;36m7\u001b[0m\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Actual Cost: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0111</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Actual Cost: \u001b[1;36m0.0111\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> accuracy </span>┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.5714   </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 7       </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1.0             </span>│\n",
       "└──────────┴─────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m0.5714  \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m7      \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m1.0            \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└──────────┴─────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# now, do the actual labeling\n",
    "verify_ds = agent.run(verify_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "59777587-3757-4d4b-9a6e-46922b1b555c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/scratch/dzhang5/visa/visa39/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> accuracy </span>┃<span style=\"font-weight: bold\"> support </span>┃<span style=\"font-weight: bold\"> completion_rate </span>┃<span style=\"font-weight: bold\"> classification_report                                 </span>┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 0.6667   </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 9       </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> 1.0             </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">               precision    recall  f1-score   support </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                                                       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">           No       1.00      0.67      0.80         9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          Yes       0.00      0.00      0.00         0 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                                                       </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">     accuracy                           0.67         9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">    macro avg       0.50      0.33      0.40         9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\"> weighted avg       1.00      0.67      0.80         9 </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">          </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">         </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                 </span>│<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">                                                       </span>│\n",
       "└──────────┴─────────┴─────────────────┴───────────────────────────────────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━┳━━━━━━━━━┳━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1maccuracy\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1msupport\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mcompletion_rate\u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mclassification_report                                \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━╇━━━━━━━━━╇━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[1;36m \u001b[0m\u001b[1;36m0.6667  \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m9      \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m1.0            \u001b[0m\u001b[1;36m \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m              precision    recall  f1-score   support\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m                                                     \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m          No       1.00      0.67      0.80         9\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m         Yes       0.00      0.00      0.00         0\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m                                                     \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m    accuracy                           0.67         9\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m   macro avg       0.50      0.33      0.40         9\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36mweighted avg       1.00      0.67      0.80         9\u001b[0m\u001b[1;36m \u001b[0m│\n",
       "│\u001b[1;36m          \u001b[0m│\u001b[1;36m         \u001b[0m│\u001b[1;36m                 \u001b[0m│\u001b[1;36m \u001b[0m\u001b[1;36m                                                     \u001b[0m\u001b[1;36m \u001b[0m│\n",
       "└──────────┴─────────┴─────────────────┴───────────────────────────────────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "metrics = verify_ds.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6130d151-0d22-4156-a456-0b52d897efac",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_test_data[f'{verify_answer_column}_label'] = verify_ds.df[f'{verify_answer_column}_label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288fcfb-7934-434a-aa70-2c03e51b5144",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds.df['text_idx'] = new_test_data['text_idx']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64ba58de-265c-4ec5-9e22-ba2497e09257",
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_ds.df.to_csv(output_verify_path, index=False)\n",
    "verify_ds.df.to_pickle(output_verify_path.replace('.csv', '.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77168401-84f4-4c23-a4cc-3ca9613cac79",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result = construct_results(last_results, new_test_data, f'{label_column}_label', f'{verify_answer_column}_label', \"text_idx\", pos_column, label_symbol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f40a09-e1e0-4781-85fb-63d91caf9b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_result.to_csv(output_final_path, index=False)\n",
    "new_result.to_pickle(output_final_path.replace('.csv', '.pkl'))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
