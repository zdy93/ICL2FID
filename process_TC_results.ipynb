{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:01.978445900Z",
     "start_time": "2024-03-10T07:39:01.353816100Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.display import display\n",
    "import argparse\n",
    "import os\n",
    "import json\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe0c568c3614da69",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:02.040271200Z",
     "start_time": "2024-03-10T07:39:01.954363600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_dir = '/scratch/dzhang5/LLM/TWEET-FID/'\n",
    "output_dir = '/scratch/dzhang5/LLM/TWEET-FID/unlabeled-results-autolabel-mv/0.1'\n",
    "model_name = \"refuel-llm\"\n",
    "few_shot_selection = \"semantic_similarity\"\n",
    "text_column = \"context\"\n",
    "verified = False\n",
    "last_result_dir = '/scratch/dzhang5/LLM/TWEET-FID/unlabeled-results-autolabel-ner-qa-mv/0.1'\n",
    "use_current_explanation = True\n",
    "use_ground_explanation = False\n",
    "raw_data_path = '/scratch/dzhang5/usda_project/tweet-fid-application/tweet-fid-unlabeled.p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e3c6cf8d0a40b95",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:10.759858500Z",
     "start_time": "2024-03-10T07:39:02.799595300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlabeled_data = pd.read_pickle(raw_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fe53e3c84d9dbc41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:10.832875200Z",
     "start_time": "2024-03-10T07:39:10.779858300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unlabeled_data.rename(columns={'tweet_token':\"tweet_tokens\"}, inplace=True)\n",
    "unlabeled_data.rename(columns={'tweet_text':\"tweet\"},inplace=True)\n",
    "unlabeled_data.loc[unlabeled_data['tweet'].str.contains('\\r'), 'tweet'] = unlabeled_data['tweet'].loc[unlabeled_data['tweet'].str.contains('\\r')].str.replace('\\r', '')\n",
    "unlabeled_data['id'] = unlabeled_data['id'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b82ab465ac29db2a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:13.691596Z",
     "start_time": "2024-03-10T07:39:13.589990Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def process_merge_results():\n",
    "    word_suffix_name = f'unlabeled-{ix}.csv'\n",
    "    word_data_path = os.path.join(data_dir, word_suffix_name)\n",
    "    ori_df = pd.read_csv(word_data_path)\n",
    "    predictions_list = []\n",
    "    for label_type in ['Food', 'Location', 'Symptom', 'Keyword']:\n",
    "        if verified:\n",
    "            output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_' + label_type + '_final_' + os.path.split(word_data_path)[-1]\n",
    "        else:\n",
    "            output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_' + label_type + '_' + os.path.split(word_data_path)[-1]\n",
    "        output_path = os.path.join(last_result_dir, output_name)\n",
    "        predictions = pd.read_csv(output_path)\n",
    "        predictions_list.append(predictions)\n",
    "    merged_predictions = predictions_list[0]\n",
    "    for i in range(1, len(predictions_list)):\n",
    "        next_prediction = predictions_list[i]\n",
    "        assert (merged_predictions[text_column] == next_prediction[text_column]).all()\n",
    "        cols_to_merge = next_prediction.columns.difference(merged_predictions.columns)\n",
    "        merged_predictions = merged_predictions.join(next_prediction[cols_to_merge], validate='1:1')\n",
    "    assert (ori_df['context'] == merged_predictions['context']).all()\n",
    "    merged_predictions['All_answer_successfully_labeled'] = (merged_predictions['Food_answer_successfully_labeled'] & merged_predictions['Location_answer_successfully_labeled'] & merged_predictions['Symptom_answer_successfully_labeled'] & merged_predictions['Keyword_answer_successfully_labeled'])\n",
    "    labeled_df = ori_df.loc[merged_predictions['All_answer_successfully_labeled']].copy()\n",
    "    labeled_df.reset_index(inplace=True)\n",
    "    labeled_df.rename(columns={'index':'ori_index'},inplace=True)\n",
    "    keep_predictions = merged_predictions.loc[merged_predictions['All_answer_successfully_labeled']].copy()\n",
    "    keep_predictions.reset_index(inplace=True)\n",
    "    keep_predictions.rename(columns={'index':'ori_index'},inplace=True)\n",
    "    cols_to_join = [f'{label_type}_answer_label' for label_type in ['Food', 'Location', 'Symptom', 'Keyword']]\n",
    "    labeled_df = labeled_df.join(keep_predictions[cols_to_join], validate='1:1')\n",
    "    labeled_df['batch_idx'] = ix\n",
    "    return labeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a897b4374d7f05ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:15.379865Z",
     "start_time": "2024-03-10T07:39:15.153583200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def extract_data():\n",
    "    suffix_name = f'unlabeled-first-{ix}.csv'\n",
    "    if verified:\n",
    "        agg_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_aggregated_final_' + suffix_name\n",
    "    else:\n",
    "        agg_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_aggregated_' + suffix_name\n",
    "    agg_path = os.path.join(last_result_dir, agg_name)\n",
    "    ori_df = pd.read_csv(agg_path)\n",
    "    output_name = os.path.split(model_name)[-1] + '_' + few_shot_selection + '_COT_' + '_cur_' + str(use_current_explanation) + '_ground_' + str(use_ground_explanation) + '_' + os.path.split(agg_path)[-1]\n",
    "    output_path = os.path.join(output_dir, output_name)\n",
    "    predictions = pd.read_csv(output_path)\n",
    "    assert (ori_df['tweet'] == predictions['tweet']).all()\n",
    "    display(predictions['sentence_class_successfully_labeled'].value_counts())\n",
    "    labeled_df = ori_df.loc[predictions['sentence_class_successfully_labeled']].copy()\n",
    "    unlabeled_df = ori_df.loc[~predictions['sentence_class_successfully_labeled']].copy()\n",
    "    keep_predictions = predictions.loc[predictions['sentence_class_successfully_labeled']].copy()\n",
    "    labeled_df = labeled_df.join(keep_predictions[['sentence_class_label']], validate='1:1')\n",
    "    labeled_df['batch_idx'] = ix\n",
    "    unlabeled_df['batch_idx'] = ix\n",
    "    return labeled_df, unlabeled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "514b2c0a858b2581",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:30.833552300Z",
     "start_time": "2024-03-10T07:39:16.705805Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     237\n",
       "False     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     424\n",
       "False     12\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     188\n",
       "False    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    401\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     367\n",
       "False     19\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     487\n",
       "False     13\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    558\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    346\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     319\n",
       "False     14\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    346\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    316\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     298\n",
       "False     46\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True    334\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     238\n",
       "False     83\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     381\n",
       "False     45\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     733\n",
       "False    256\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     645\n",
       "False    184\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     411\n",
       "False     69\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     411\n",
       "False     72\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "sentence_class_successfully_labeled\n",
       "True     418\n",
       "False     76\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "labeled_df_list, unlabeled_df_list, word_labeled_df_list = [], [], []\n",
    "for ix in range(1, 21):\n",
    "    labeled_df, unlabeled_df = extract_data()\n",
    "    labeled_df_list.append(labeled_df)\n",
    "    unlabeled_df_list.append(unlabeled_df)\n",
    "    word_labeled_df = process_merge_results()\n",
    "    word_labeled_df_list.append(word_labeled_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16209e59b4d35e20",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:39:51.418528900Z",
     "start_time": "2024-03-10T07:39:51.361947600Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_df = pd.concat(labeled_df_list)\n",
    "unlabeled_df = pd.concat(unlabeled_df_list)\n",
    "word_labeled_df = pd.concat(word_labeled_df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ade855cae653db14",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:40:00.814664600Z",
     "start_time": "2024-03-10T07:40:00.653367Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8955, 36) (7858, 35)\n"
     ]
    }
   ],
   "source": [
    "print(word_labeled_df.shape, labeled_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11357b9635ae12c3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:40:04.850519Z",
     "start_time": "2024-03-10T07:40:04.778419500Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word_keep_columns = ['Food_answer_label', 'Location_answer_label','Symptom_answer_label', 'Keyword_answer_label']\n",
    "full_labeled_df = labeled_df.join(word_labeled_df.set_index('id')[word_keep_columns], on='id', validate='1:1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a49a00361d48134c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-10T07:40:07.570868300Z",
     "start_time": "2024-03-10T07:40:07.324341800Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "full_labeled_df.to_pickle(f'/scratch/dzhang5/LLM/TWEET-FID/full_labeled_{model_name}_{few_shot_selection}.p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "5b93bb543764b485",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T07:11:01.423313600Z",
     "start_time": "2024-03-09T07:11:00.086492700Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_df = pd.merge(labeled_df, unlabeled_data[['id', 'tweet_tokens']], how='left', on='id', validate='1:1', suffixes=['_drop', ''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "206c8d2b7a4890d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T07:11:47.244997600Z",
     "start_time": "2024-03-09T07:11:47.002912200Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labeled_df.drop(columns=['tweet_tokens_drop'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "6e4c208959618b50",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T07:44:11.072170400Z",
     "start_time": "2024-03-09T07:44:10.769063Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "token_label_map = {'Food':'food', 'Location':'loc', 'Symptom':'symptom', 'Keyword':'other'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "50cbd3950dd768c6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-09T08:27:39.756028600Z",
     "start_time": "2024-03-09T08:27:39.663885300Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def convert_token_labels(tweet_tokens, entity_dict):\n",
    "    def get_index(wp, tp):\n",
    "        if word_list[wp].startswith(tweet_tokens[tp]):\n",
    "            if wp == wlen-1:\n",
    "                return [tp]\n",
    "            elif tp == tlen - 1:\n",
    "                return []\n",
    "            else:\n",
    "                rest_ans = get_index(wp+1, tp+1)\n",
    "                if rest_ans:\n",
    "                    return [tp] + rest_ans\n",
    "                else:\n",
    "                    return []\n",
    "        return []\n",
    "    entity_dict = json.loads(entity_dict)\n",
    "    tlen = len(tweet_tokens)\n",
    "    ans_list = ['O']*tlen\n",
    "    for k, v in entity_dict.items():\n",
    "        for word in v:\n",
    "            word_list = word.split()\n",
    "            wlen = len(word_list)\n",
    "            all_index_list = [get_index(0, i) for i in range(tlen)]\n",
    "            all_index_list = [_ for _ in all_index_list if _]\n",
    "            if len(all_index_list) > 1:\n",
    "                warnings.warn(f\"multiple match of {word} in {tweet_tokens}\")\n",
    "            elif len(all_index_list) == 0:\n",
    "                warnings.warn(f\"no match of {word} in {tweet_tokens}\")\n",
    "            else:\n",
    "                index_list = all_index_list[0]\n",
    "                for e, ix in enumerate(index_list):\n",
    "                    if ans_list[ix] != 'O':\n",
    "                        warnings.warn(f\"multiple types of entity match the same word: {word}\")\n",
    "                    if e == 0:\n",
    "                        label = f'B-{token_label_map[k]}'\n",
    "                    else:\n",
    "                        label = f'I-{token_label_map[k]}'\n",
    "                    ans_list[ix] = label\n",
    "    return ans_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.9-visa",
   "language": "python",
   "name": "py3.9-visa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
